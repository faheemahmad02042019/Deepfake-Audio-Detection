{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake or Real: Classical ML Baselines for Deepfake Audio Detection\n",
    "**By Faheem Ahmad**\n",
    "\n",
    "Local version for Mac M4 (Apple Silicon GPU via MPS) â€” equivalent to the Colab notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T18:05:50.128138Z",
     "iopub.status.busy": "2026-02-14T18:05:50.127911Z",
     "iopub.status.idle": "2026-02-14T18:05:51.838414Z",
     "shell.execute_reply": "2026-02-14T18:05:51.838194Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch device: mps\n",
      "Apple M4 GPU available: True\n",
      "PyTorch version: 2.10.0\n",
      "torchaudio version: 2.10.0\n",
      "GPU smoke test passed (256x256 matmul on mps)\n",
      "All imports successful!\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# 0) Imports & Setup (Local Mac M4 GPU)\n",
    "# =========================================\n",
    "import os, glob, warnings, hashlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.feature as LF\n",
    "import soundfile as sf\n",
    "from scipy import signal, stats\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # non-interactive backend for local run\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from itertools import combinations\n",
    "from scipy.stats import chi2\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    GroupKFold, GroupShuffleSplit, StratifiedKFold,\n",
    "    GridSearchCV, train_test_split\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, roc_auc_score, roc_curve, auc,\n",
    "    confusion_matrix, classification_report, det_curve\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import (\n",
    "    LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    ")\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# GPU: Apple M4 via PyTorch MPS + torchaudio for GPU-accelerated audio\n",
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "\n",
    "DEVICE = torch.device('mps') if torch.backends.mps.is_available() else torch.device('cpu')\n",
    "print(f'PyTorch device: {DEVICE}')\n",
    "print(f'Apple M4 GPU available: {torch.backends.mps.is_available()}')\n",
    "print(f'PyTorch version: {torch.__version__}')\n",
    "print(f'torchaudio version: {torchaudio.__version__}')\n",
    "\n",
    "# Quick GPU smoke test\n",
    "_t = torch.randn(256, 256, device=DEVICE)\n",
    "_ = torch.mm(_t, _t)\n",
    "print(f'GPU smoke test passed (256x256 matmul on {DEVICE})')\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['figure.dpi'] = 130\n",
    "\n",
    "SEED = 4\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "print('All imports successful!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T18:05:51.851418Z",
     "iopub.status.busy": "2026-02-14T18:05:51.851168Z",
     "iopub.status.idle": "2026-02-14T18:05:51.853441Z",
     "shell.execute_reply": "2026-02-14T18:05:51.853251Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: /Users/faheemahmad/Downloads/FoR_root/for-2sec/for-2seconds/training/fake\n",
      "OK: /Users/faheemahmad/Downloads/FoR_root/for-2sec/for-2seconds/training/real\n",
      "OK: /Users/faheemahmad/Downloads/FoR_root/for-2sec/for-2seconds/testing/fake\n",
      "OK: /Users/faheemahmad/Downloads/FoR_root/for-2sec/for-2seconds/testing/real\n",
      "OK: /Users/faheemahmad/Downloads/FoR_root/for-2sec/for-2seconds/validation/fake\n",
      "OK: /Users/faheemahmad/Downloads/FoR_root/for-2sec/for-2seconds/validation/real\n",
      "OK: /Users/faheemahmad/Downloads/FoR_root/for-rerec/for-rerecorded/training/fake\n",
      "OK: /Users/faheemahmad/Downloads/FoR_root/for-rerec/for-rerecorded/training/real\n",
      "OK: /Users/faheemahmad/Downloads/FoR_root/for-rerec/for-rerecorded/testing/fake\n",
      "OK: /Users/faheemahmad/Downloads/FoR_root/for-rerec/for-rerecorded/testing/real\n",
      "OK: /Users/faheemahmad/Downloads/FoR_root/for-rerec/for-rerecorded/validation/fake\n",
      "OK: /Users/faheemahmad/Downloads/FoR_root/for-rerec/for-rerecorded/validation/real\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# 1) Configuration & Dataset Paths (Local)\n",
    "# =========================================\n",
    "\n",
    "# LOCAL path to the FoR dataset (unzipped from FoR_root.zip)\n",
    "BASE_DIR = os.path.expanduser('~/Downloads/FoR_root')\n",
    "\n",
    "# Subpaths to search\n",
    "SUBSETS = [\n",
    "    'for-2sec/for-2seconds/training/fake',\n",
    "    'for-2sec/for-2seconds/training/real',\n",
    "    'for-2sec/for-2seconds/testing/fake',\n",
    "    'for-2sec/for-2seconds/testing/real',\n",
    "    'for-2sec/for-2seconds/validation/fake',\n",
    "    'for-2sec/for-2seconds/validation/real',\n",
    "    'for-rerec/for-rerecorded/training/fake',\n",
    "    'for-rerec/for-rerecorded/training/real',\n",
    "    'for-rerec/for-rerecorded/testing/fake',\n",
    "    'for-rerec/for-rerecorded/testing/real',\n",
    "    'for-rerec/for-rerecorded/validation/fake',\n",
    "    'for-rerec/for-rerecorded/validation/real',\n",
    "]\n",
    "\n",
    "# Verify dataset exists\n",
    "assert os.path.isdir(BASE_DIR), f'Dataset not found at {BASE_DIR}. Unzip FoR_root.zip first.'\n",
    "\n",
    "for rel in SUBSETS:\n",
    "    full_path = os.path.join(BASE_DIR, rel)\n",
    "    exists = os.path.isdir(full_path)\n",
    "    print(f\"{'OK' if exists else 'MISSING'}: {full_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T18:05:51.854396Z",
     "iopub.status.busy": "2026-02-14T18:05:51.854316Z",
     "iopub.status.idle": "2026-02-14T18:05:55.522475Z",
     "shell.execute_reply": "2026-02-14T18:05:55.522195Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repair summary -> Repaired: 0 | Dropped: 0\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# 2) Auto-Repair: Normalize audio to 16kHz\n",
    "#    mono PCM WAV, remove broken/silent files\n",
    "# =========================================\n",
    "\n",
    "# Thresholds\n",
    "MIN_FILESIZE_BYTES = 8_000\n",
    "MIN_DURATION_SEC   = 0.20\n",
    "TARGET_SR          = 16000\n",
    "\n",
    "def _looks_suspicious(fname):\n",
    "    low = fname.lower()\n",
    "    bad_suffixes = [\n",
    "        '.mp3.wav', '.m4a.wav', '.aac.wav', '.ogg.wav', '.wma.wav',\n",
    "        '.wav_mono.wav', '.wav_norm.wav', '.wav_silence.wav', '_2sec.wav'\n",
    "    ]\n",
    "    return (any(low.endswith(suf) for suf in bad_suffixes) or\n",
    "            low.endswith(('.mp3', '.m4a', '.aac', '.ogg', '.wma', '.flac')))\n",
    "\n",
    "def _safe_decode(path, sr=TARGET_SR):\n",
    "    try:\n",
    "        y, srr = librosa.load(path, sr=sr, mono=True)\n",
    "        return y, sr\n",
    "    except Exception:\n",
    "        return None, None\n",
    "\n",
    "def _reencode_to_wav(src_path):\n",
    "    y, sr = _safe_decode(src_path, sr=TARGET_SR)\n",
    "    if y is None or len(y) == 0:\n",
    "        return None\n",
    "    base, _ = os.path.splitext(src_path)\n",
    "    for suf in ['.mp3', '.m4a', '.aac', '.ogg', '.wma', '.flac',\n",
    "                '.wav_mono', '.wav_norm', '.wav_silence', '_2sec']:\n",
    "        if base.lower().endswith(suf):\n",
    "            base = base[:-len(suf)]\n",
    "    out_path = base + '.wav'\n",
    "    sf.write(out_path, y, TARGET_SR, subtype='PCM_16')\n",
    "    if os.path.abspath(out_path) != os.path.abspath(src_path) and os.path.exists(src_path):\n",
    "        try: os.remove(src_path)\n",
    "        except: pass\n",
    "    return out_path\n",
    "\n",
    "def _is_silent(y, sr):\n",
    "    if y is None or len(y) == 0:\n",
    "        return True\n",
    "    if len(y) / sr < MIN_DURATION_SEC:\n",
    "        return True\n",
    "    rms = np.sqrt(np.mean(y**2)) if len(y) else 0.0\n",
    "    return bool(rms < 1e-4)\n",
    "\n",
    "repaired, dropped = 0, 0\n",
    "all_candidates = glob.glob(os.path.join(BASE_DIR, '**/*.*'), recursive=True)\n",
    "\n",
    "for p in all_candidates:\n",
    "    if not os.path.isfile(p):\n",
    "        continue\n",
    "    if not p.lower().endswith(('.wav', '.mp3', '.m4a', '.aac', '.ogg', '.wma', '.flac')):\n",
    "        continue\n",
    "    try:\n",
    "        if os.path.getsize(p) < MIN_FILESIZE_BYTES:\n",
    "            os.remove(p)\n",
    "            dropped += 1\n",
    "            continue\n",
    "    except: pass\n",
    "\n",
    "    if _looks_suspicious(p) or not p.lower().endswith('.wav'):\n",
    "        out = _reencode_to_wav(p)\n",
    "        if out is None:\n",
    "            try: os.remove(p)\n",
    "            except: pass\n",
    "            dropped += 1\n",
    "            continue\n",
    "        else:\n",
    "            repaired += 1\n",
    "            p = out\n",
    "\n",
    "    y, sr = _safe_decode(p, sr=TARGET_SR)\n",
    "    if y is None or _is_silent(y, sr):\n",
    "        try: os.remove(p)\n",
    "        except: pass\n",
    "        dropped += 1\n",
    "\n",
    "print(f'Repair summary -> Repaired: {repaired} | Dropped: {dropped}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T18:05:55.523544Z",
     "iopub.status.busy": "2026-02-14T18:05:55.523475Z",
     "iopub.status.idle": "2026-02-14T18:05:55.608616Z",
     "shell.execute_reply": "2026-02-14T18:05:55.608403Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usable files: 31138 | Class counts [real(0), fake(1)]: [15548 15590]\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# 2b) Discover paths, labels, groups\n",
    "# =========================================\n",
    "\n",
    "def derive_group_from_filename(path):\n",
    "    stem = os.path.splitext(os.path.basename(path))[0]\n",
    "    if '_' in stem:\n",
    "        return stem.split('_')[0]\n",
    "    h = hashlib.md5(stem.encode('utf-8')).hexdigest()[:8]\n",
    "    return f'spk{h}'\n",
    "\n",
    "def discover_paths_labels_groups(base_dir):\n",
    "    X_paths, y, groups = [], [], []\n",
    "    for rel in SUBSETS:\n",
    "        full = os.path.join(base_dir, rel)\n",
    "        label = 1 if full.lower().endswith('fake') else 0\n",
    "        subset_tag = 'for-2seconds' if 'for-2seconds' in full.lower() else 'for-rerecorded'\n",
    "        if not os.path.isdir(full):\n",
    "            continue\n",
    "        for fname in os.listdir(full):\n",
    "            fpath = os.path.join(full, fname)\n",
    "            if os.path.isfile(fpath) and fname.lower().endswith('.wav'):\n",
    "                X_paths.append(fpath)\n",
    "                y.append(label)\n",
    "                groups.append(f'{subset_tag}:{derive_group_from_filename(fpath)}')\n",
    "    if not X_paths:\n",
    "        raise RuntimeError('No usable WAV files. Check BASE_DIR and folder structure.')\n",
    "    return X_paths, np.array(y, dtype=int), np.array(groups)\n",
    "\n",
    "paths, labels, groups = discover_paths_labels_groups(BASE_DIR)\n",
    "print(f'Usable files: {len(paths)} | Class counts [real(0), fake(1)]: {np.bincount(labels)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T18:05:55.609682Z",
     "iopub.status.busy": "2026-02-14T18:05:55.609605Z",
     "iopub.status.idle": "2026-02-14T18:09:24.396554Z",
     "shell.execute_reply": "2026-02-14T18:09:24.396256Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Feature extraction at 44.1 kHz (25ms window, 10ms hop) ===\n",
      "Using device: mps for spectral features\n",
      "[44k_25ms] Extracting prosody features (CPU parallel, all cores)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Prosody done in 109.5s\n",
      "[44k_25ms] Extracting spectral features (GPU MPS accelerated)...\n",
      "  ... 5000/31138 spectral features extracted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ... 10000/31138 spectral features extracted\n",
      "  ... 15000/31138 spectral features extracted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ... 20000/31138 spectral features extracted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ... 25000/31138 spectral features extracted\n",
      "  ... 30000/31138 spectral features extracted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Spectral (GPU) done in 1.2s\n",
      "[44k_25ms] Prosody shape: (31138, 24) | Spectral shape: (31138, 14) | Combined: (31138, 36)\n",
      "\n",
      "=== Feature extraction at 16 kHz (full-clip features) ===\n",
      "[16k_fullclip] Extracting prosody features (CPU parallel, all cores)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Prosody done in 96.7s\n",
      "[16k_fullclip] Extracting spectral features (GPU MPS accelerated)...\n",
      "  ... 5000/31138 spectral features extracted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ... 10000/31138 spectral features extracted\n",
      "  ... 15000/31138 spectral features extracted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ... 20000/31138 spectral features extracted\n",
      "  ... 25000/31138 spectral features extracted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ... 30000/31138 spectral features extracted\n",
      "  Spectral (GPU) done in 1.2s\n",
      "[16k_fullclip] Prosody shape: (31138, 24) | Spectral shape: (31138, 14) | Combined: (31138, 36)\n",
      "\n",
      "--- Sample of 44.1kHz feature table ---\n",
      "   label                      group  \\\n",
      "0      1   for-2seconds:file100.wav   \n",
      "1      1  for-2seconds:file1000.wav   \n",
      "2      1  for-2seconds:file1001.wav   \n",
      "3      1  for-2seconds:file1004.wav   \n",
      "4      1  for-2seconds:file1005.wav   \n",
      "\n",
      "                                                path  dur_s   f0_mean_v  \\\n",
      "0  /Users/faheemahmad/Downloads/FoR_root/for-2sec...    2.0  175.158454   \n",
      "1  /Users/faheemahmad/Downloads/FoR_root/for-2sec...    2.0  166.648128   \n",
      "2  /Users/faheemahmad/Downloads/FoR_root/for-2sec...    2.0  181.722854   \n",
      "3  /Users/faheemahmad/Downloads/FoR_root/for-2sec...    2.0  163.803925   \n",
      "4  /Users/faheemahmad/Downloads/FoR_root/for-2sec...    2.0  139.108427   \n",
      "\n",
      "    f0_std_v   f0_iqr_v   f0_cv_v  f0_range_v    f0_p10_v  ...  \\\n",
      "0  33.073217  43.605222  0.188819  126.252631  132.337780  ...   \n",
      "1  49.259811  45.900886  0.295592  210.498934  112.508825  ...   \n",
      "2  33.451886  56.641081  0.184082  169.551678  147.449576  ...   \n",
      "3  31.575223  42.484884  0.192762  114.013925  119.964925  ...   \n",
      "4  31.198473  37.999779  0.224274  154.597780  115.868670  ...   \n",
      "\n",
      "   spec_centroid_rng  spec_bandwidth_mean  spec_bandwidth_std  \\\n",
      "0                NaN                  NaN                 NaN   \n",
      "1                NaN                  NaN                 NaN   \n",
      "2                NaN                  NaN                 NaN   \n",
      "3                NaN                  NaN                 NaN   \n",
      "4                NaN                  NaN                 NaN   \n",
      "\n",
      "   spec_bandwidth_rng  spec_contrast_mean  spec_contrast_std  \\\n",
      "0                 NaN                 NaN                NaN   \n",
      "1                 NaN                 NaN                NaN   \n",
      "2                 NaN                 NaN                NaN   \n",
      "3                 NaN                 NaN                NaN   \n",
      "4                 NaN                 NaN                NaN   \n",
      "\n",
      "   spec_rolloff_mean  spec_rolloff_std  spec_rolloff_rng    sr_tag  \n",
      "0                NaN               NaN               NaN  44k_25ms  \n",
      "1                NaN               NaN               NaN  44k_25ms  \n",
      "2                NaN               NaN               NaN  44k_25ms  \n",
      "3                NaN               NaN               NaN  44k_25ms  \n",
      "4                NaN               NaN               NaN  44k_25ms  \n",
      "\n",
      "[5 rows x 36 columns]\n",
      "\n",
      "Shape: (31138, 36)\n",
      "\n",
      "--- Sample of 16kHz feature table ---\n",
      "   label                      group  \\\n",
      "0      1   for-2seconds:file100.wav   \n",
      "1      1  for-2seconds:file1000.wav   \n",
      "2      1  for-2seconds:file1001.wav   \n",
      "3      1  for-2seconds:file1004.wav   \n",
      "4      1  for-2seconds:file1005.wav   \n",
      "\n",
      "                                                path  dur_s   f0_mean_v  \\\n",
      "0  /Users/faheemahmad/Downloads/FoR_root/for-2sec...    2.0  176.243183   \n",
      "1  /Users/faheemahmad/Downloads/FoR_root/for-2sec...    2.0  171.031696   \n",
      "2  /Users/faheemahmad/Downloads/FoR_root/for-2sec...    2.0  182.620101   \n",
      "3  /Users/faheemahmad/Downloads/FoR_root/for-2sec...    2.0  164.088732   \n",
      "4  /Users/faheemahmad/Downloads/FoR_root/for-2sec...    2.0  141.984881   \n",
      "\n",
      "    f0_std_v   f0_iqr_v   f0_cv_v  f0_range_v    f0_p10_v  ...  \\\n",
      "0  32.822282  42.070242  0.186233  129.397256  132.937748  ...   \n",
      "1  44.698655  44.446687  0.261347  203.312477  131.934429  ...   \n",
      "2  31.908092  55.580806  0.174724  113.798320  150.202459  ...   \n",
      "3  30.755697  41.618698  0.187433  111.016806  118.808499  ...   \n",
      "4  29.507826  37.606658  0.207824  152.247264  117.538754  ...   \n",
      "\n",
      "   spec_centroid_rng  spec_bandwidth_mean  spec_bandwidth_std  \\\n",
      "0                NaN                  NaN                 NaN   \n",
      "1                NaN                  NaN                 NaN   \n",
      "2                NaN                  NaN                 NaN   \n",
      "3                NaN                  NaN                 NaN   \n",
      "4                NaN                  NaN                 NaN   \n",
      "\n",
      "   spec_bandwidth_rng  spec_contrast_mean  spec_contrast_std  \\\n",
      "0                 NaN                 NaN                NaN   \n",
      "1                 NaN                 NaN                NaN   \n",
      "2                 NaN                 NaN                NaN   \n",
      "3                 NaN                 NaN                NaN   \n",
      "4                 NaN                 NaN                NaN   \n",
      "\n",
      "   spec_rolloff_mean  spec_rolloff_std  spec_rolloff_rng        sr_tag  \n",
      "0                NaN               NaN               NaN  16k_fullclip  \n",
      "1                NaN               NaN               NaN  16k_fullclip  \n",
      "2                NaN               NaN               NaN  16k_fullclip  \n",
      "3                NaN               NaN               NaN  16k_fullclip  \n",
      "4                NaN               NaN               NaN  16k_fullclip  \n",
      "\n",
      "[5 rows x 36 columns]\n",
      "\n",
      "Shape: (31138, 36)\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# 3) Feature Extraction at 44.1kHz AND 16kHz\n",
    "#    GPU-ACCELERATED: torchaudio spectral features on MPS\n",
    "#    CPU parallel: librosa prosody features (F0/YIN)\n",
    "# =========================================\n",
    "\n",
    "import time\n",
    "\n",
    "# Shared constants\n",
    "TARGET_SR_16K = 16000\n",
    "HOP_16K       = 160       # ~10 ms at 16 kHz\n",
    "FRAME_16K     = 1024\n",
    "\n",
    "SR_44100      = 44100\n",
    "FRAME_44K     = int(round(0.025 * SR_44100))   # 25 ms window\n",
    "HOP_44K       = int(round(0.010 * SR_44100))   # 10 ms hop\n",
    "\n",
    "F0_FMIN       = 50\n",
    "F0_FMAX       = 500\n",
    "\n",
    "# ---- Stats helper ----\n",
    "def _safe_stats(x):\n",
    "    x = np.asarray(x, float)\n",
    "    x = x[np.isfinite(x)]\n",
    "    if x.size == 0:\n",
    "        return dict(mean=np.nan, std=np.nan, p10=np.nan, p90=np.nan,\n",
    "                    iqr=np.nan, rng=np.nan, cv=np.nan)\n",
    "    q10, q90 = np.quantile(x, [0.10, 0.90])\n",
    "    iqr = np.quantile(x, 0.75) - np.quantile(x, 0.25)\n",
    "    rng = x.max() - x.min()\n",
    "    std = x.std()\n",
    "    mean = x.mean()\n",
    "    cv = std / mean if mean else np.nan\n",
    "    return dict(mean=mean, std=std, p10=q10, p90=q90, iqr=iqr, rng=rng, cv=cv)\n",
    "\n",
    "# ---- Prosody extraction (CPU - librosa YIN needs CPU) ----\n",
    "def extract_prosody_generic(path, sr, hop_length, frame_len):\n",
    "    y, sr = librosa.load(path, sr=sr, mono=True)\n",
    "    y, _ = librosa.effects.trim(y, top_db=30)\n",
    "    dur_s = len(y) / sr if sr else np.nan\n",
    "\n",
    "    f0 = librosa.yin(\n",
    "        y, fmin=F0_FMIN, fmax=F0_FMAX, sr=sr,\n",
    "        frame_length=frame_len, hop_length=hop_length\n",
    "    )\n",
    "    rms = librosa.feature.rms(\n",
    "        y=y, frame_length=frame_len, hop_length=hop_length\n",
    "    ).ravel()\n",
    "\n",
    "    voiced_mask = np.isfinite(f0) & (f0 > 0) & (rms > (0.5 * np.median(rms)))\n",
    "\n",
    "    if np.any(voiced_mask):\n",
    "        idx = np.where(voiced_mask)[0]\n",
    "        f0_interp = np.interp(np.arange(f0.size), idx, f0[idx])\n",
    "    else:\n",
    "        f0_interp = np.full_like(f0, np.nan, dtype=float)\n",
    "\n",
    "    t = np.arange(f0.size) * (hop_length / sr)\n",
    "    f0_stats_v = _safe_stats(f0[voiced_mask])\n",
    "    rms_stats = _safe_stats(rms)\n",
    "\n",
    "    jitter = (np.median(np.abs(np.diff(f0[voiced_mask]))) / np.median(f0[voiced_mask])\n",
    "              if np.sum(voiced_mask) > 1 and np.median(f0[voiced_mask]) > 0 else np.nan)\n",
    "    shimmer = (np.median(np.abs(np.diff(rms[voiced_mask]))) / np.median(rms[voiced_mask])\n",
    "               if np.sum(voiced_mask) > 1 and np.median(rms[voiced_mask]) > 0 else np.nan)\n",
    "\n",
    "    slope = (np.polyfit(t[np.isfinite(f0_interp)],\n",
    "                        f0_interp[np.isfinite(f0_interp)], 1)[0]\n",
    "             if np.sum(np.isfinite(f0_interp)) >= 2 else np.nan)\n",
    "\n",
    "    segs = np.diff(np.concatenate([[0], voiced_mask.astype(int), [0]]))\n",
    "    starts = np.where(segs == 1)[0]\n",
    "    ends = np.where(segs == -1)[0]\n",
    "    voiced_durs = (ends - starts) * (hop_length / sr)\n",
    "    voice_pct = (np.sum(voiced_durs) / dur_s) if dur_s else np.nan\n",
    "\n",
    "    return dict(\n",
    "        dur_s=dur_s,\n",
    "        f0_mean_v=f0_stats_v['mean'], f0_std_v=f0_stats_v['std'],\n",
    "        f0_iqr_v=f0_stats_v['iqr'], f0_cv_v=f0_stats_v['cv'],\n",
    "        f0_range_v=f0_stats_v['rng'], f0_p10_v=f0_stats_v['p10'],\n",
    "        f0_p90_v=f0_stats_v['p90'],\n",
    "        rms_mean=rms_stats['mean'], rms_std=rms_stats['std'],\n",
    "        rms_cv=rms_stats['cv'], rms_iqr=rms_stats['iqr'],\n",
    "        rms_range=rms_stats['rng'],\n",
    "        jitter_local=jitter, shimmer_local=shimmer,\n",
    "        f0_slope_hz_per_s=slope,\n",
    "        voice_pct=voice_pct,\n",
    "        n_voiced_seg_per_s=(len(voiced_durs) / dur_s if dur_s else np.nan),\n",
    "        mean_voiced_seg_ms=(np.mean(voiced_durs) * 1000 if len(voiced_durs) else np.nan),\n",
    "        pause_ratio=(1.0 - voice_pct if voice_pct == voice_pct else np.nan),\n",
    "        hnr_mean=np.nan\n",
    "    )\n",
    "\n",
    "# =========================================================\n",
    "# GPU-ACCELERATED spectral extraction using torchaudio + MPS\n",
    "# =========================================================\n",
    "def extract_spectral_gpu(path, sr, hop_length, n_fft):\n",
    "    \"\"\"Extract spectral features using torchaudio on Apple M4 GPU (MPS).\"\"\"\n",
    "    # Load audio with torchaudio\n",
    "    waveform, orig_sr = torchaudio.load(path)\n",
    "\n",
    "    # Resample on GPU if needed\n",
    "    if orig_sr != sr:\n",
    "        resampler = T.Resample(orig_sr, sr).to(DEVICE)\n",
    "        waveform = waveform.to(DEVICE)\n",
    "        waveform = resampler(waveform)\n",
    "    else:\n",
    "        waveform = waveform.to(DEVICE)\n",
    "\n",
    "    # Mono\n",
    "    if waveform.shape[0] > 1:\n",
    "        waveform = waveform.mean(dim=0, keepdim=True)\n",
    "\n",
    "    # Trim silence using energy threshold on GPU\n",
    "    energy = waveform.abs().squeeze()\n",
    "    threshold = energy.max() * (10 ** (-25 / 20))  # top_db=25\n",
    "    above_thresh = torch.where(energy > threshold)[0]\n",
    "    if len(above_thresh) > 0:\n",
    "        waveform = waveform[:, above_thresh[0]:above_thresh[-1]+1]\n",
    "\n",
    "    # GPU-accelerated spectrogram (STFT on MPS)\n",
    "    spectrogram_transform = T.Spectrogram(\n",
    "        n_fft=n_fft, hop_length=hop_length,\n",
    "        power=2.0, normalized=False\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    spec = spectrogram_transform(waveform)  # [1, freq_bins, time_frames]\n",
    "\n",
    "    # Compute spectral features on GPU\n",
    "    freqs = torch.linspace(0, sr / 2, spec.shape[1], device=DEVICE)\n",
    "\n",
    "    # Spectral centroid: weighted mean of frequencies\n",
    "    spec_sum = spec.squeeze().sum(dim=0) + 1e-10\n",
    "    centroid = (freqs.unsqueeze(1) * spec.squeeze()).sum(dim=0) / spec_sum\n",
    "\n",
    "    # Spectral bandwidth: weighted std of frequencies\n",
    "    deviation = (freqs.unsqueeze(1) - centroid.unsqueeze(0)) ** 2\n",
    "    bandwidth = torch.sqrt((deviation * spec.squeeze()).sum(dim=0) / spec_sum)\n",
    "\n",
    "    # Spectral rolloff (85%)\n",
    "    cumsum = torch.cumsum(spec.squeeze(), dim=0)\n",
    "    total_energy = cumsum[-1, :] + 1e-10\n",
    "    rolloff_threshold = 0.85 * total_energy\n",
    "    rolloff_bins = (cumsum >= rolloff_threshold.unsqueeze(0)).int().argmax(dim=0)\n",
    "    rolloff = freqs[rolloff_bins]\n",
    "\n",
    "    # Spectral contrast (simplified: max - min per band)\n",
    "    n_bands = min(6, spec.shape[1] // 2)\n",
    "    band_size = spec.shape[1] // n_bands\n",
    "    contrast_vals = []\n",
    "    for b in range(n_bands):\n",
    "        band = spec.squeeze()[b*band_size:(b+1)*band_size, :]\n",
    "        contrast_vals.append((band.max(dim=0).values - band.min(dim=0).values).mean())\n",
    "    contrast_mean = torch.stack(contrast_vals).mean()\n",
    "    contrast_std = torch.stack(contrast_vals).std()\n",
    "\n",
    "    # Move results to CPU for stats\n",
    "    centroid_np = centroid.cpu().numpy()\n",
    "    bandwidth_np = bandwidth.cpu().numpy()\n",
    "    rolloff_np = rolloff.cpu().numpy()\n",
    "\n",
    "    def _s(x):\n",
    "        x = np.asarray(x, float)\n",
    "        return dict(mean=float(np.mean(x)), std=float(np.std(x)), rng=float(np.ptp(x)))\n",
    "\n",
    "    cs, bs, rs = _s(centroid_np), _s(bandwidth_np), _s(rolloff_np)\n",
    "\n",
    "    return dict(\n",
    "        spec_centroid_mean=cs['mean'], spec_centroid_std=cs['std'],\n",
    "        spec_centroid_rng=cs['rng'],\n",
    "        spec_bandwidth_mean=bs['mean'], spec_bandwidth_std=bs['std'],\n",
    "        spec_bandwidth_rng=bs['rng'],\n",
    "        spec_contrast_mean=float(contrast_mean.cpu()),\n",
    "        spec_contrast_std=float(contrast_std.cpu()),\n",
    "        spec_rolloff_mean=rs['mean'], spec_rolloff_std=rs['std'],\n",
    "        spec_rolloff_rng=rs['rng'],\n",
    "    )\n",
    "\n",
    "# ---- Build feature table ----\n",
    "def build_feature_table(paths, labels, groups, sr, hop_length, frame_len, tag):\n",
    "    def _one_p(p, y, g):\n",
    "        try:\n",
    "            f = extract_prosody_generic(p, sr=sr, hop_length=hop_length, frame_len=frame_len)\n",
    "        except Exception:\n",
    "            f = {k: np.nan for k in [\n",
    "                'dur_s','f0_mean_v','f0_std_v','f0_iqr_v','f0_cv_v','f0_range_v',\n",
    "                'f0_p10_v','f0_p90_v','rms_mean','rms_std','rms_cv','rms_iqr',\n",
    "                'rms_range','jitter_local','shimmer_local','f0_slope_hz_per_s',\n",
    "                'voice_pct','n_voiced_seg_per_s','mean_voiced_seg_ms',\n",
    "                'pause_ratio','hnr_mean'\n",
    "            ]}\n",
    "        f.update(dict(path=p, label=int(y), group=g))\n",
    "        return f\n",
    "\n",
    "    def _one_s_gpu(p, y, g):\n",
    "        \"\"\"GPU-accelerated spectral feature extraction.\"\"\"\n",
    "        try:\n",
    "            f = extract_spectral_gpu(p, sr=sr, hop_length=hop_length, n_fft=frame_len)\n",
    "        except Exception:\n",
    "            f = {k: np.nan for k in [\n",
    "                'spec_centroid_mean','spec_centroid_std','spec_centroid_rng',\n",
    "                'spec_bandwidth_mean','spec_bandwidth_std','spec_bandwidth_rng',\n",
    "                'spec_contrast_mean','spec_contrast_std',\n",
    "                'spec_rolloff_mean','spec_rolloff_std','spec_rolloff_rng'\n",
    "            ]}\n",
    "        f.update(dict(path=p, label=int(y), group=g))\n",
    "        return f\n",
    "\n",
    "    # Prosody: parallel on all CPU cores (YIN is CPU-only)\n",
    "    print(f'[{tag}] Extracting prosody features (CPU parallel, all cores)...')\n",
    "    t0 = time.time()\n",
    "    prosody_rows = Parallel(n_jobs=-1, prefer='threads')(\n",
    "        delayed(_one_p)(p, y, g) for p, y, g in zip(paths, labels, groups)\n",
    "    )\n",
    "    df_prosody = pd.DataFrame(prosody_rows)\n",
    "    df_prosody = df_prosody[['label', 'group', 'path'] +\n",
    "                            [c for c in df_prosody.columns\n",
    "                             if c not in ['label', 'group', 'path']]]\n",
    "    print(f'  Prosody done in {time.time()-t0:.1f}s')\n",
    "\n",
    "    # Spectral: GPU-accelerated via torchaudio on MPS\n",
    "    print(f'[{tag}] Extracting spectral features (GPU MPS accelerated)...')\n",
    "    t0 = time.time()\n",
    "    spec_rows = []\n",
    "    for i, (p, y, g) in enumerate(zip(paths, labels, groups)):\n",
    "        spec_rows.append(_one_s_gpu(p, y, g))\n",
    "        if (i + 1) % 5000 == 0:\n",
    "            print(f'  ... {i+1}/{len(paths)} spectral features extracted')\n",
    "    df_spec = pd.DataFrame(spec_rows)\n",
    "    df_spec = df_spec[['label', 'group', 'path'] +\n",
    "                      [c for c in df_spec.columns\n",
    "                       if c not in ['label', 'group', 'path']]]\n",
    "    print(f'  Spectral (GPU) done in {time.time()-t0:.1f}s')\n",
    "\n",
    "    df_all = df_prosody.merge(df_spec, on=['path', 'label', 'group'], how='outer')\n",
    "    df_all['sr_tag'] = tag\n",
    "\n",
    "    print(f'[{tag}] Prosody shape: {df_prosody.shape}'\n",
    "          f' | Spectral shape: {df_spec.shape}'\n",
    "          f' | Combined: {df_all.shape}')\n",
    "    return df_all\n",
    "\n",
    "# --- Extract at BOTH sample rates ---\n",
    "print('=== Feature extraction at 44.1 kHz (25ms window, 10ms hop) ===')\n",
    "print(f'Using device: {DEVICE} for spectral features')\n",
    "df_all_44k = build_feature_table(\n",
    "    paths, labels, groups,\n",
    "    sr=SR_44100, hop_length=HOP_44K, frame_len=FRAME_44K,\n",
    "    tag='44k_25ms'\n",
    ")\n",
    "\n",
    "print('\\n=== Feature extraction at 16 kHz (full-clip features) ===')\n",
    "df_all_16k = build_feature_table(\n",
    "    paths, labels, groups,\n",
    "    sr=TARGET_SR_16K, hop_length=HOP_16K, frame_len=FRAME_16K,\n",
    "    tag='16k_fullclip'\n",
    ")\n",
    "\n",
    "# Show sample\n",
    "print('\\n--- Sample of 44.1kHz feature table ---')\n",
    "print(df_all_44k.head())\n",
    "print(f'\\nShape: {df_all_44k.shape}')\n",
    "print('\\n--- Sample of 16kHz feature table ---')\n",
    "print(df_all_16k.head())\n",
    "print(f'\\nShape: {df_all_16k.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T18:09:24.398152Z",
     "iopub.status.busy": "2026-02-14T18:09:24.398016Z",
     "iopub.status.idle": "2026-02-14T18:09:25.142050Z",
     "shell.execute_reply": "2026-02-14T18:09:25.141625Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Visualizations for 44k_25ms ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ANOVA + Missing-value summary for 44k_25ms ===\n",
      "\n",
      "Top 10 most significant features (smallest p):\n",
      "          feature  F_statistic        p_value\n",
      "9         rms_std  1540.662372   0.000000e+00\n",
      "2        f0_std_v  5237.854095   0.000000e+00\n",
      "3        f0_iqr_v  1682.366878   0.000000e+00\n",
      "4         f0_cv_v  5130.223076   0.000000e+00\n",
      "5      f0_range_v  3502.242116   0.000000e+00\n",
      "6        f0_p10_v  1994.017893   0.000000e+00\n",
      "8        rms_mean  2081.873560   0.000000e+00\n",
      "11        rms_iqr  1957.391791   0.000000e+00\n",
      "14  shimmer_local   468.813751   0.000000e+00\n",
      "12      rms_range  1028.015115  5.997354e-222\n",
      "\n",
      "Bottom 10 least significant features (largest p):\n",
      "               feature  F_statistic        p_value\n",
      "10              rms_cv   641.489322  4.168805e-140\n",
      "7             f0_p90_v   625.141183  1.272546e-136\n",
      "18  mean_voiced_seg_ms   536.422913  1.120360e-117\n",
      "16           voice_pct   494.157046  1.245431e-108\n",
      "19         pause_ratio   494.157046  1.245431e-108\n",
      "13        jitter_local   331.160563   1.294311e-73\n",
      "15   f0_slope_hz_per_s   274.953313   1.735308e-61\n",
      "0                dur_s   145.462327   2.020457e-33\n",
      "17  n_voiced_seg_per_s    86.551919   1.447387e-20\n",
      "1            f0_mean_v     7.014764   8.088106e-03\n",
      "\n",
      "Overall missing values (44k_25ms): 373,656 of 1,120,968 cells (33.33% missing)\n",
      "\n",
      "                     missing_count  missing_percent\n",
      "spec_bandwidth_mean          31138            100.0\n",
      "spec_rolloff_rng             31138            100.0\n",
      "spec_rolloff_std             31138            100.0\n",
      "spec_rolloff_mean            31138            100.0\n",
      "spec_contrast_std            31138            100.0\n",
      "spec_contrast_mean           31138            100.0\n",
      "spec_bandwidth_rng           31138            100.0\n",
      "spec_bandwidth_std           31138            100.0\n",
      "spec_centroid_rng            31138            100.0\n",
      "spec_centroid_std            31138            100.0\n",
      "spec_centroid_mean           31138            100.0\n",
      "hnr_mean                     31138            100.0\n",
      "mean_voiced_seg_ms               0              0.0\n",
      "n_voiced_seg_per_s               0              0.0\n",
      "label                            0              0.0\n",
      "pause_ratio                      0              0.0\n",
      "group                            0              0.0\n",
      "voice_pct                        0              0.0\n",
      "f0_slope_hz_per_s                0              0.0\n",
      "shimmer_local                    0              0.0\n",
      "f0_range_v                       0              0.0\n",
      "path                             0              0.0\n",
      "dur_s                            0              0.0\n",
      "f0_mean_v                        0              0.0\n",
      "f0_std_v                         0              0.0\n",
      "f0_iqr_v                         0              0.0\n",
      "f0_cv_v                          0              0.0\n",
      "f0_p10_v                         0              0.0\n",
      "jitter_local                     0              0.0\n",
      "f0_p90_v                         0              0.0\n",
      "rms_mean                         0              0.0\n",
      "rms_std                          0              0.0\n",
      "rms_cv                           0              0.0\n",
      "rms_iqr                          0              0.0\n",
      "rms_range                        0              0.0\n",
      "sr_tag                           0              0.0\n",
      "\n",
      "=== Visualizations for 16k_fullclip ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ANOVA + Missing-value summary for 16k_fullclip ===\n",
      "\n",
      "Top 10 most significant features (smallest p):\n",
      "       feature  F_statistic        p_value\n",
      "2     f0_std_v  4931.438067   0.000000e+00\n",
      "3     f0_iqr_v  1681.157598   0.000000e+00\n",
      "4      f0_cv_v  4224.231672   0.000000e+00\n",
      "5   f0_range_v  3981.260401   0.000000e+00\n",
      "8     rms_mean  2181.676416   0.000000e+00\n",
      "9      rms_std  1176.938123  3.290414e-253\n",
      "10      rms_cv  1160.128541  1.092384e-249\n",
      "7     f0_p90_v  1106.917513  1.573798e-238\n",
      "11     rms_iqr  1097.296968  1.646012e-236\n",
      "12   rms_range  1084.169065  9.400655e-234\n",
      "\n",
      "Bottom 10 least significant features (largest p):\n",
      "               feature  F_statistic        p_value\n",
      "17  n_voiced_seg_per_s   927.004669  1.164632e-200\n",
      "6             f0_p10_v   836.718092  1.423252e-181\n",
      "18  mean_voiced_seg_ms   727.214320  2.392369e-158\n",
      "15   f0_slope_hz_per_s   175.689587   5.433386e-40\n",
      "0                dur_s   147.413964   7.599739e-34\n",
      "1            f0_mean_v    42.365594   7.685995e-11\n",
      "13        jitter_local    36.598264   1.468145e-09\n",
      "16           voice_pct     5.136218   2.343847e-02\n",
      "19         pause_ratio     5.136218   2.343847e-02\n",
      "14       shimmer_local     0.012878   9.096495e-01\n",
      "\n",
      "Overall missing values (16k_fullclip): 373,656 of 1,120,968 cells (33.33% missing)\n",
      "\n",
      "                     missing_count  missing_percent\n",
      "spec_bandwidth_mean          31138            100.0\n",
      "spec_rolloff_rng             31138            100.0\n",
      "spec_rolloff_std             31138            100.0\n",
      "spec_rolloff_mean            31138            100.0\n",
      "spec_contrast_std            31138            100.0\n",
      "spec_contrast_mean           31138            100.0\n",
      "spec_bandwidth_rng           31138            100.0\n",
      "spec_bandwidth_std           31138            100.0\n",
      "spec_centroid_rng            31138            100.0\n",
      "spec_centroid_std            31138            100.0\n",
      "spec_centroid_mean           31138            100.0\n",
      "hnr_mean                     31138            100.0\n",
      "mean_voiced_seg_ms               0              0.0\n",
      "n_voiced_seg_per_s               0              0.0\n",
      "label                            0              0.0\n",
      "pause_ratio                      0              0.0\n",
      "group                            0              0.0\n",
      "voice_pct                        0              0.0\n",
      "f0_slope_hz_per_s                0              0.0\n",
      "shimmer_local                    0              0.0\n",
      "f0_range_v                       0              0.0\n",
      "path                             0              0.0\n",
      "dur_s                            0              0.0\n",
      "f0_mean_v                        0              0.0\n",
      "f0_std_v                         0              0.0\n",
      "f0_iqr_v                         0              0.0\n",
      "f0_cv_v                          0              0.0\n",
      "f0_p10_v                         0              0.0\n",
      "jitter_local                     0              0.0\n",
      "f0_p90_v                         0              0.0\n",
      "rms_mean                         0              0.0\n",
      "rms_std                          0              0.0\n",
      "rms_cv                           0              0.0\n",
      "rms_iqr                          0              0.0\n",
      "rms_range                        0              0.0\n",
      "sr_tag                           0              0.0\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# 4) EDA: Visualizations & ANOVA\n",
    "# =========================================\n",
    "\n",
    "def run_visuals(df_all, tag):\n",
    "    print(f'\\n=== Visualizations for {tag} ===')\n",
    "    n_per_class = 3000\n",
    "    df_viz = (df_all.groupby('label', group_keys=False)\n",
    "                    .apply(lambda d: d.sample(min(len(d), n_per_class),\n",
    "                                              random_state=SEED))\n",
    "                    .reset_index(drop=True))\n",
    "\n",
    "    def split_by_label(df, col):\n",
    "        a = df.loc[df['label'] == 0, col].replace([np.inf, -np.inf], np.nan).dropna().to_numpy()\n",
    "        b = df.loc[df['label'] == 1, col].replace([np.inf, -np.inf], np.nan).dropna().to_numpy()\n",
    "        return a, b\n",
    "\n",
    "    # F0 distribution\n",
    "    real, fake = split_by_label(df_viz, 'f0_mean_v')\n",
    "    fig, ax = plt.subplots(figsize=(7, 4))\n",
    "    ax.hist(real, bins=50, alpha=0.6, label='real (0)')\n",
    "    ax.hist(fake, bins=50, alpha=0.6, label='fake (1)')\n",
    "    ax.set_title(f'Distribution: f0_mean_v ({tag})')\n",
    "    ax.set_xlabel('f0_mean_v (Hz)')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.legend()\n",
    "    fig.savefig(os.path.expanduser(f'~/Downloads/f0_dist_{tag}.png'), bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    # Spectral centroid distribution\n",
    "    real, fake = split_by_label(df_viz, 'spec_centroid_mean')\n",
    "    fig, ax = plt.subplots(figsize=(7, 4))\n",
    "    ax.hist(real, bins=50, alpha=0.6, label='real (0)')\n",
    "    ax.hist(fake, bins=50, alpha=0.6, label='fake (1)')\n",
    "    ax.set_title(f'Distribution: spectral centroid mean ({tag})')\n",
    "    ax.set_xlabel('spec_centroid_mean (Hz)')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.legend()\n",
    "    fig.savefig(os.path.expanduser(f'~/Downloads/centroid_dist_{tag}.png'), bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    # Scatter: centroid vs bandwidth\n",
    "    x0 = df_viz.loc[df_viz['label'] == 0, 'spec_centroid_mean'].to_numpy()\n",
    "    y0 = df_viz.loc[df_viz['label'] == 0, 'spec_bandwidth_mean'].to_numpy()\n",
    "    x1 = df_viz.loc[df_viz['label'] == 1, 'spec_centroid_mean'].to_numpy()\n",
    "    y1 = df_viz.loc[df_viz['label'] == 1, 'spec_bandwidth_mean'].to_numpy()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7, 5))\n",
    "    ax.scatter(x0, y0, s=10, alpha=0.5, marker='o', label='real (0)')\n",
    "    ax.scatter(x1, y1, s=10, alpha=0.5, marker='x', label='fake (1)')\n",
    "    ax.set_title(f'Spectral Centroid vs Bandwidth ({tag})')\n",
    "    ax.set_xlabel('spec_centroid_mean')\n",
    "    ax.set_ylabel('spec_bandwidth_mean')\n",
    "    ax.legend()\n",
    "    fig.savefig(os.path.expanduser(f'~/Downloads/scatter_{tag}.png'), bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def run_anova_and_missing(df_all, tag):\n",
    "    print(f'\\n=== ANOVA + Missing-value summary for {tag} ===')\n",
    "    exclude = ['label', 'path', 'group', 'sr_tag']\n",
    "    predictor_cols = [c for c in df_all.columns\n",
    "                      if c not in exclude and np.issubdtype(df_all[c].dtype, np.number)]\n",
    "\n",
    "    anova_results = []\n",
    "    for col in predictor_cols:\n",
    "        real_vals = df_all[df_all['label'] == 0][col].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "        fake_vals = df_all[df_all['label'] == 1][col].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "        if len(real_vals) > 0 and len(fake_vals) > 0:\n",
    "            F, p = stats.f_oneway(real_vals, fake_vals)\n",
    "            anova_results.append((col, F, p))\n",
    "\n",
    "    df_anova = pd.DataFrame(anova_results, columns=['feature', 'F_statistic', 'p_value'])\n",
    "    df_anova = df_anova.sort_values('p_value')\n",
    "    print('\\nTop 10 most significant features (smallest p):')\n",
    "    print(df_anova.head(10))\n",
    "    print('\\nBottom 10 least significant features (largest p):')\n",
    "    print(df_anova.tail(10))\n",
    "\n",
    "    null_abs = df_all.isna().sum()\n",
    "    null_pct = (df_all.isna().mean() * 100).round(2)\n",
    "    df_null_summary = pd.DataFrame({\n",
    "        'missing_count': null_abs, 'missing_percent': null_pct\n",
    "    }).sort_values('missing_percent', ascending=False)\n",
    "\n",
    "    total_missing = df_all.isna().sum().sum()\n",
    "    total_cells = df_all.size\n",
    "    overall_pct = round((total_missing / total_cells) * 100, 2)\n",
    "    print(f'\\nOverall missing values ({tag}): '\n",
    "          f'{total_missing:,} of {total_cells:,} cells ({overall_pct}% missing)\\n')\n",
    "    print(df_null_summary)\n",
    "\n",
    "    return df_anova, df_null_summary\n",
    "\n",
    "# Run for both sample rates\n",
    "run_visuals(df_all_44k, '44k_25ms')\n",
    "anova_44k, null_44k = run_anova_and_missing(df_all_44k, '44k_25ms')\n",
    "\n",
    "run_visuals(df_all_16k, '16k_fullclip')\n",
    "anova_16k, null_16k = run_anova_and_missing(df_all_16k, '16k_fullclip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T18:09:25.144467Z",
     "iopub.status.busy": "2026-02-14T18:09:25.144103Z",
     "iopub.status.idle": "2026-02-14T18:25:22.014490Z",
     "shell.execute_reply": "2026-02-14T18:25:22.014193Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ MODELLING for 44k_25ms ================\n",
      "\n",
      "Features USED [20]: ['dur_s', 'f0_mean_v', 'f0_std_v', 'f0_iqr_v', 'f0_cv_v', 'f0_range_v', 'f0_p10_v', 'f0_p90_v', 'rms_mean', 'rms_std', 'rms_cv', 'rms_iqr', 'rms_range', 'jitter_local', 'shimmer_local', 'f0_slope_hz_per_s', 'voice_pct', 'n_voiced_seg_per_s', 'mean_voiced_seg_ms', 'pause_ratio']\n",
      "Features DROPPED [12]:\n",
      "  - hnr_mean: 100% missing\n",
      "  - spec_centroid_mean: 100% missing\n",
      "  - spec_centroid_std: 100% missing\n",
      "  - spec_centroid_rng: 100% missing\n",
      "  - spec_bandwidth_mean: 100% missing\n",
      "  - spec_bandwidth_std: 100% missing\n",
      "  - spec_bandwidth_rng: 100% missing\n",
      "  - spec_contrast_mean: 100% missing\n",
      "  - spec_contrast_std: 100% missing\n",
      "  - spec_rolloff_mean: 100% missing\n",
      "  - spec_rolloff_std: 100% missing\n",
      "  - spec_rolloff_rng: 100% missing\n",
      "\n",
      "Train shape: (24913, 20) | Test shape: (6225, 20)\n",
      "\n",
      "Tuning RBF SVM (CV, ROC-AUC)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x107f71bc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RBF params: {'C': 10, 'gamma': 'scale'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== LogisticRegression (44k_25ms) ==\n",
      "[TRAIN] Acc: 0.7117 | AUC: 0.7830 | EER: 28.83%\n",
      "[TEST]  Acc: 0.7102 | AUC: 0.7806 | EER: 28.98%\n",
      "  FAR@EER: 0.2901 | FRR@EER: 0.2895\n",
      "Classification report (TEST):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7145    0.7099    0.7122      3144\n",
      "           1     0.7059    0.7105    0.7082      3081\n",
      "\n",
      "    accuracy                         0.7102      6225\n",
      "   macro avg     0.7102    0.7102    0.7102      6225\n",
      "weighted avg     0.7102    0.7102    0.7102      6225\n",
      "\n",
      "\n",
      "== LDA (44k_25ms) ==\n",
      "[TRAIN] Acc: 0.7077 | AUC: 0.7728 | EER: 29.23%\n",
      "[TEST]  Acc: 0.7028 | AUC: 0.7699 | EER: 29.72%\n",
      "  FAR@EER: 0.2974 | FRR@EER: 0.2970\n",
      "Classification report (TEST):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7071    0.7026    0.7049      3144\n",
      "           1     0.6985    0.7030    0.7007      3081\n",
      "\n",
      "    accuracy                         0.7028      6225\n",
      "   macro avg     0.7028    0.7028    0.7028      6225\n",
      "weighted avg     0.7028    0.7028    0.7028      6225\n",
      "\n",
      "\n",
      "== QDA (44k_25ms) ==\n",
      "[TRAIN] Acc: 0.7257 | AUC: 0.7955 | EER: 27.43%\n",
      "[TEST]  Acc: 0.7272 | AUC: 0.7999 | EER: 27.28%\n",
      "  FAR@EER: 0.2729 | FRR@EER: 0.2726\n",
      "Classification report (TEST):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7313    0.7271    0.7292      3144\n",
      "           1     0.7231    0.7274    0.7252      3081\n",
      "\n",
      "    accuracy                         0.7272      6225\n",
      "   macro avg     0.7272    0.7272    0.7272      6225\n",
      "weighted avg     0.7273    0.7272    0.7272      6225\n",
      "\n",
      "\n",
      "== GaussianNB (44k_25ms) ==\n",
      "[TRAIN] Acc: 0.6966 | AUC: 0.7652 | EER: 30.34%\n",
      "[TEST]  Acc: 0.6930 | AUC: 0.7628 | EER: 30.70%\n",
      "  FAR@EER: 0.3069 | FRR@EER: 0.3070\n",
      "Classification report (TEST):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6973    0.6931    0.6952      3144\n",
      "           1     0.6887    0.6930    0.6908      3081\n",
      "\n",
      "    accuracy                         0.6930      6225\n",
      "   macro avg     0.6930    0.6930    0.6930      6225\n",
      "weighted avg     0.6930    0.6930    0.6930      6225\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== SVM_linear (44k_25ms) ==\n",
      "[TRAIN] Acc: 0.7166 | AUC: 0.7815 | EER: 28.34%\n",
      "[TEST]  Acc: 0.7141 | AUC: 0.7770 | EER: 28.59%\n",
      "  FAR@EER: 0.2859 | FRR@EER: 0.2859\n",
      "Classification report (TEST):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7182    0.7141    0.7161      3144\n",
      "           1     0.7099    0.7141    0.7120      3081\n",
      "\n",
      "    accuracy                         0.7141      6225\n",
      "   macro avg     0.7140    0.7141    0.7140      6225\n",
      "weighted avg     0.7141    0.7141    0.7141      6225\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== SVM_rbf (44k_25ms) ==\n",
      "[TRAIN] Acc: 0.8786 | AUC: 0.9471 | EER: 12.14%\n",
      "[TEST]  Acc: 0.8535 | AUC: 0.9312 | EER: 14.65%\n",
      "  FAR@EER: 0.1466 | FRR@EER: 0.1464\n",
      "Classification report (TEST):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8561    0.8534    0.8547      3144\n",
      "           1     0.8509    0.8536    0.8522      3081\n",
      "\n",
      "    accuracy                         0.8535      6225\n",
      "   macro avg     0.8535    0.8535    0.8535      6225\n",
      "weighted avg     0.8535    0.8535    0.8535      6225\n",
      "\n",
      "\n",
      "== GMM_logL_diff (44k_25ms) ==\n",
      "[TRAIN] Acc: 0.7247 | AUC: 0.8101 | EER: 27.53%\n",
      "[TEST]  Acc: 0.7224 | AUC: 0.8061 | EER: 27.76%\n",
      "Classification report (TEST):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7263    0.7226    0.7245      3144\n",
      "           1     0.7184    0.7222    0.7203      3081\n",
      "\n",
      "    accuracy                         0.7224      6225\n",
      "   macro avg     0.7224    0.7224    0.7224      6225\n",
      "weighted avg     0.7224    0.7224    0.7224      6225\n",
      "\n",
      "\n",
      "=== Summary metrics (sorted by TEST ROC-AUC) for 44k_25ms ===\n",
      "                model  accuracy_train  roc_auc_train  eer_train  \\\n",
      "5             SVM_rbf        0.878577       0.947086   0.121423   \n",
      "6       GMM_logL_diff        0.724722       0.810066   0.275278   \n",
      "2                 QDA        0.725726       0.795491   0.274274   \n",
      "0  LogisticRegression        0.711717       0.783002   0.288283   \n",
      "4          SVM_linear        0.716574       0.781522   0.283426   \n",
      "1                 LDA        0.707663       0.772773   0.292337   \n",
      "3          GaussianNB        0.696624       0.765210   0.303376   \n",
      "\n",
      "   far_at_eer_train  frr_at_eer_train  accuracy   roc_auc       eer  \\\n",
      "5          0.121412          0.121433  0.853494  0.931174  0.146505   \n",
      "6          0.275314          0.275242  0.722410  0.806071  0.277593   \n",
      "2          0.274266          0.274283  0.727229  0.799864  0.272770   \n",
      "0          0.288294          0.288272  0.710201  0.780571  0.289796   \n",
      "4          0.283296          0.283556  0.714056  0.777050  0.285944   \n",
      "1          0.292325          0.292350  0.702811  0.769894  0.297187   \n",
      "3          0.303370          0.303382  0.693012  0.762796  0.306989   \n",
      "\n",
      "   far_at_eer  frr_at_eer  \n",
      "5    0.146628    0.146381  \n",
      "6    0.277354    0.277832  \n",
      "2    0.272901    0.272639  \n",
      "0    0.290076    0.289516  \n",
      "4    0.285941    0.285946  \n",
      "1    0.297392    0.296981  \n",
      "3    0.306934    0.307043  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ MODELLING for 16k_fullclip ================\n",
      "\n",
      "Features USED [19]: ['dur_s', 'f0_mean_v', 'f0_std_v', 'f0_iqr_v', 'f0_cv_v', 'f0_range_v', 'f0_p10_v', 'f0_p90_v', 'rms_mean', 'rms_std', 'rms_cv', 'rms_iqr', 'rms_range', 'jitter_local', 'f0_slope_hz_per_s', 'voice_pct', 'n_voiced_seg_per_s', 'mean_voiced_seg_ms', 'pause_ratio']\n",
      "Features DROPPED [13]:\n",
      "  - shimmer_local: ANOVA p >= 0.05\n",
      "  - hnr_mean: 100% missing\n",
      "  - spec_centroid_mean: 100% missing\n",
      "  - spec_centroid_std: 100% missing\n",
      "  - spec_centroid_rng: 100% missing\n",
      "  - spec_bandwidth_mean: 100% missing\n",
      "  - spec_bandwidth_std: 100% missing\n",
      "  - spec_bandwidth_rng: 100% missing\n",
      "  - spec_contrast_mean: 100% missing\n",
      "  - spec_contrast_std: 100% missing\n",
      "  - spec_rolloff_mean: 100% missing\n",
      "  - spec_rolloff_std: 100% missing\n",
      "  - spec_rolloff_rng: 100% missing\n",
      "\n",
      "Train shape: (24913, 19) | Test shape: (6225, 19)\n",
      "\n",
      "Tuning RBF SVM (CV, ROC-AUC)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x107b71bc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RBF params: {'C': 10, 'gamma': 'scale'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== LogisticRegression (16k_fullclip) ==\n",
      "[TRAIN] Acc: 0.7041 | AUC: 0.7686 | EER: 29.59%\n",
      "[TEST]  Acc: 0.6977 | AUC: 0.7636 | EER: 30.23%\n",
      "  FAR@EER: 0.3025 | FRR@EER: 0.3022\n",
      "Classification report (TEST):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7020    0.6975    0.6997      3144\n",
      "           1     0.6933    0.6978    0.6956      3081\n",
      "\n",
      "    accuracy                         0.6977      6225\n",
      "   macro avg     0.6977    0.6977    0.6977      6225\n",
      "weighted avg     0.6977    0.6977    0.6977      6225\n",
      "\n",
      "\n",
      "== LDA (16k_fullclip) ==\n",
      "[TRAIN] Acc: 0.7022 | AUC: 0.7657 | EER: 29.78%\n",
      "[TEST]  Acc: 0.6964 | AUC: 0.7603 | EER: 30.36%\n",
      "  FAR@EER: 0.3038 | FRR@EER: 0.3035\n",
      "Classification report (TEST):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7007    0.6962    0.6985      3144\n",
      "           1     0.6920    0.6965    0.6943      3081\n",
      "\n",
      "    accuracy                         0.6964      6225\n",
      "   macro avg     0.6964    0.6964    0.6964      6225\n",
      "weighted avg     0.6964    0.6964    0.6964      6225\n",
      "\n",
      "\n",
      "== QDA (16k_fullclip) ==\n",
      "[TRAIN] Acc: 0.7199 | AUC: 0.7899 | EER: 28.01%\n",
      "[TEST]  Acc: 0.7206 | AUC: 0.7902 | EER: 27.94%\n",
      "  FAR@EER: 0.2793 | FRR@EER: 0.2795\n",
      "Classification report (TEST):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7247    0.7207    0.7227      3144\n",
      "           1     0.7166    0.7205    0.7186      3081\n",
      "\n",
      "    accuracy                         0.7206      6225\n",
      "   macro avg     0.7206    0.7206    0.7206      6225\n",
      "weighted avg     0.7207    0.7206    0.7206      6225\n",
      "\n",
      "\n",
      "== GaussianNB (16k_fullclip) ==\n",
      "[TRAIN] Acc: 0.6953 | AUC: 0.7623 | EER: 30.47%\n",
      "[TEST]  Acc: 0.6957 | AUC: 0.7615 | EER: 30.43%\n",
      "  FAR@EER: 0.3041 | FRR@EER: 0.3044\n",
      "Classification report (TEST):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6999    0.6959    0.6979      3144\n",
      "           1     0.6915    0.6956    0.6935      3081\n",
      "\n",
      "    accuracy                         0.6957      6225\n",
      "   macro avg     0.6957    0.6957    0.6957      6225\n",
      "weighted avg     0.6958    0.6957    0.6957      6225\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== SVM_linear (16k_fullclip) ==\n",
      "[TRAIN] Acc: 0.7077 | AUC: 0.7659 | EER: 29.23%\n",
      "[TEST]  Acc: 0.7051 | AUC: 0.7579 | EER: 29.49%\n",
      "  FAR@EER: 0.2952 | FRR@EER: 0.2947\n",
      "Classification report (TEST):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7093    0.7048    0.7071      3144\n",
      "           1     0.7007    0.7053    0.7030      3081\n",
      "\n",
      "    accuracy                         0.7051      6225\n",
      "   macro avg     0.7050    0.7051    0.7050      6225\n",
      "weighted avg     0.7051    0.7051    0.7051      6225\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x103d89bc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x106971bc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x104cf1bc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x104155bc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x106f71bc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x106f71bc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x102dddbc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x1121c9bc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x107171bc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== SVM_rbf (16k_fullclip) ==\n",
      "[TRAIN] Acc: 0.8651 | AUC: 0.9360 | EER: 13.49%\n",
      "[TEST]  Acc: 0.8432 | AUC: 0.9217 | EER: 15.68%\n",
      "  FAR@EER: 0.1568 | FRR@EER: 0.1568\n",
      "Classification report (TEST):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8459    0.8432    0.8445      3144\n",
      "           1     0.8405    0.8432    0.8419      3081\n",
      "\n",
      "    accuracy                         0.8432      6225\n",
      "   macro avg     0.8432    0.8432    0.8432      6225\n",
      "weighted avg     0.8432    0.8432    0.8432      6225\n",
      "\n",
      "\n",
      "== GMM_logL_diff (16k_fullclip) ==\n",
      "[TRAIN] Acc: 0.7443 | AUC: 0.8175 | EER: 25.57%\n",
      "[TEST]  Acc: 0.7311 | AUC: 0.8074 | EER: 26.89%\n",
      "Classification report (TEST):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7350    0.7312    0.7331      3144\n",
      "           1     0.7272    0.7309    0.7290      3081\n",
      "\n",
      "    accuracy                         0.7311      6225\n",
      "   macro avg     0.7311    0.7311    0.7311      6225\n",
      "weighted avg     0.7311    0.7311    0.7311      6225\n",
      "\n",
      "\n",
      "=== Summary metrics (sorted by TEST ROC-AUC) for 16k_fullclip ===\n",
      "                model  accuracy_train  roc_auc_train  eer_train  \\\n",
      "5             SVM_rbf        0.865091       0.936007   0.134910   \n",
      "6       GMM_logL_diff        0.744270       0.817544   0.255730   \n",
      "2                 QDA        0.719865       0.789904   0.280135   \n",
      "0  LogisticRegression        0.704130       0.768584   0.295870   \n",
      "3          GaussianNB        0.695300       0.762349   0.304701   \n",
      "1                 LDA        0.702164       0.765703   0.297836   \n",
      "4          SVM_linear        0.707743       0.765938   0.292257   \n",
      "\n",
      "   far_at_eer_train  frr_at_eer_train  accuracy   roc_auc       eer  \\\n",
      "5          0.134956          0.134863  0.843213  0.921729  0.156787   \n",
      "6          0.255643          0.255816  0.731084  0.807356  0.268917   \n",
      "2          0.280152          0.280118  0.720643  0.790225  0.279358   \n",
      "0          0.295872          0.295867  0.697671  0.763577  0.302328   \n",
      "3          0.304740          0.304661  0.695743  0.761462  0.304259   \n",
      "1          0.297807          0.297866  0.696386  0.760262  0.303613   \n",
      "4          0.292244          0.292270  0.705060  0.757861  0.294937   \n",
      "\n",
      "   far_at_eer  frr_at_eer  \n",
      "5    0.156807    0.156767  \n",
      "6    0.268766    0.269068  \n",
      "2    0.279262    0.279455  \n",
      "0    0.302481    0.302175  \n",
      "3    0.304071    0.304447  \n",
      "1    0.303753    0.303473  \n",
      "4    0.295165    0.294710  \n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# 5) Model Building & Evaluation\n",
    "#    Uses GPU (MPS) for SVM via torch where\n",
    "#    beneficial; sklearn for classical models\n",
    "# =========================================\n",
    "\n",
    "def compute_eer_and_curve(y_true, scores):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, scores)\n",
    "    fnr = 1.0 - tpr\n",
    "    abs_diffs = np.abs(fpr - fnr)\n",
    "    idx = np.argmin(abs_diffs)\n",
    "    eer = (fpr[idx] + fnr[idx]) / 2.0\n",
    "    thr = thresholds[idx]\n",
    "    return eer, thr, fpr, fnr\n",
    "\n",
    "def far_frr_at_threshold(y_true, scores, thr):\n",
    "    y_pred = (scores >= thr).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    far = fp / (fp + tn) if (fp + tn) > 0 else 0.0\n",
    "    frr = fn / (fn + tp) if (fn + tp) > 0 else 0.0\n",
    "    return far, frr\n",
    "\n",
    "def run_models(df_all, anova_df, tag):\n",
    "    print(f'\\n================ MODELLING for {tag} ================')\n",
    "\n",
    "    # Feature selection\n",
    "    sig_level = 0.05\n",
    "    weak_features_stat = anova_df.loc[anova_df['p_value'] >= sig_level, 'feature'].tolist()\n",
    "    all_nan_cols = [c for c in df_all.columns if df_all[c].isna().all()]\n",
    "    base_drop_cols = ['label', 'path', 'group', 'sr_tag']\n",
    "    drop_cols = list(set(base_drop_cols + weak_features_stat + all_nan_cols))\n",
    "\n",
    "    X = df_all.drop(columns=[c for c in drop_cols if c in df_all.columns]) \\\n",
    "             .select_dtypes(include=[np.number]).copy()\n",
    "    y = df_all['label'].astype(int).to_numpy()\n",
    "    X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "    all_nan_cols2 = X.columns[X.isna().all()].tolist()\n",
    "    if all_nan_cols2:\n",
    "        X.drop(columns=all_nan_cols2, inplace=True)\n",
    "        all_nan_cols = list(set(all_nan_cols + all_nan_cols2))\n",
    "\n",
    "    used_features = X.columns.tolist()\n",
    "\n",
    "    reason_map = {}\n",
    "    for f in weak_features_stat:\n",
    "        reason_map[f] = 'ANOVA p >= 0.05'\n",
    "    for f in all_nan_cols:\n",
    "        reason_map[f] = '100% missing'\n",
    "\n",
    "    dropped_features = [c for c in df_all.columns\n",
    "                        if c not in used_features + ['label', 'path', 'group', 'sr_tag']]\n",
    "\n",
    "    print(f'\\nFeatures USED [{len(used_features)}]: {used_features}')\n",
    "    print(f'Features DROPPED [{len(dropped_features)}]:')\n",
    "    for f in dropped_features:\n",
    "        print(f'  - {f}: {reason_map.get(f, \"Not numeric\")}')\n",
    "\n",
    "    # Train/test split (group-aware)\n",
    "    if 'group' in df_all.columns:\n",
    "        gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=SEED)\n",
    "        tr_idx, te_idx = next(gss.split(X, y, groups=df_all['group'].to_numpy()))\n",
    "    else:\n",
    "        tr_idx, te_idx = train_test_split(\n",
    "            np.arange(len(y)), test_size=0.2, stratify=y, random_state=SEED\n",
    "        )\n",
    "\n",
    "    X_train, X_test = X.iloc[tr_idx], X.iloc[te_idx]\n",
    "    y_train, y_test = y[tr_idx], y[te_idx]\n",
    "\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    scaler = StandardScaler()\n",
    "    X_train_imp = imputer.fit_transform(X_train)\n",
    "    X_test_imp = imputer.transform(X_test)\n",
    "    X_train_sc = scaler.fit_transform(X_train_imp)\n",
    "    X_test_sc = scaler.transform(X_test_imp)\n",
    "\n",
    "    print(f'\\nTrain shape: {X_train_sc.shape} | Test shape: {X_test_sc.shape}')\n",
    "\n",
    "    # Models\n",
    "    model_dict = {\n",
    "        'LogisticRegression': LogisticRegression(max_iter=1000, class_weight='balanced', random_state=SEED),\n",
    "        'LDA': LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto'),\n",
    "        'QDA': QuadraticDiscriminantAnalysis(reg_param=1e-3),\n",
    "        'GaussianNB': GaussianNB(),\n",
    "        'SVM_linear': SVC(kernel='linear', C=1.0, class_weight='balanced', random_state=SEED, probability=True),\n",
    "    }\n",
    "\n",
    "    # RBF SVM with GridSearchCV\n",
    "    base_rbf = SVC(kernel='rbf', class_weight='balanced', random_state=SEED, probability=True)\n",
    "    param_grid = {'C': [0.1, 1, 10], 'gamma': ['scale', 0.01, 0.001]}\n",
    "    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=SEED)\n",
    "    grid = GridSearchCV(base_rbf, param_grid, cv=skf, scoring='roc_auc', n_jobs=-1)\n",
    "    print('\\nTuning RBF SVM (CV, ROC-AUC)...')\n",
    "    grid.fit(X_train_sc, y_train)\n",
    "    rbf_best = grid.best_estimator_\n",
    "    print('Best RBF params:', grid.best_params_)\n",
    "    model_dict['SVM_rbf'] = rbf_best\n",
    "\n",
    "    # GMM (generative baseline)\n",
    "    gmm_real = GaussianMixture(n_components=3, covariance_type='full', random_state=SEED)\n",
    "    gmm_fake = GaussianMixture(n_components=3, covariance_type='full', random_state=SEED + 1)\n",
    "    gmm_real.fit(X_train_sc[y_train == 0])\n",
    "    gmm_fake.fit(X_train_sc[y_train == 1])\n",
    "\n",
    "    results_rows = []\n",
    "\n",
    "    def evaluate_model(name, clf):\n",
    "        clf.fit(X_train_sc, y_train)\n",
    "        if hasattr(clf, 'predict_proba'):\n",
    "            scores_train = clf.predict_proba(X_train_sc)[:, 1]\n",
    "            scores_test = clf.predict_proba(X_test_sc)[:, 1]\n",
    "        else:\n",
    "            scores_train = clf.decision_function(X_train_sc)\n",
    "            scores_test = clf.decision_function(X_test_sc)\n",
    "\n",
    "        eer_tr, thr_tr, _, _ = compute_eer_and_curve(y_train, scores_train)\n",
    "        far_tr, frr_tr = far_frr_at_threshold(y_train, scores_train, thr_tr)\n",
    "        y_pred_tr = (scores_train >= thr_tr).astype(int)\n",
    "        acc_tr = accuracy_score(y_train, y_pred_tr)\n",
    "        roc_tr = roc_auc_score(y_train, scores_train)\n",
    "\n",
    "        eer_te, thr_te, _, _ = compute_eer_and_curve(y_test, scores_test)\n",
    "        far_te, frr_te = far_frr_at_threshold(y_test, scores_test, thr_te)\n",
    "        y_pred_te = (scores_test >= thr_te).astype(int)\n",
    "        acc_te = accuracy_score(y_test, y_pred_te)\n",
    "        roc_te = roc_auc_score(y_test, scores_test)\n",
    "\n",
    "        print(f'\\n== {name} ({tag}) ==')\n",
    "        print(f'[TRAIN] Acc: {acc_tr:.4f} | AUC: {roc_tr:.4f} | EER: {eer_tr*100:.2f}%')\n",
    "        print(f'[TEST]  Acc: {acc_te:.4f} | AUC: {roc_te:.4f} | EER: {eer_te*100:.2f}%')\n",
    "        print(f'  FAR@EER: {far_te:.4f} | FRR@EER: {frr_te:.4f}')\n",
    "        print(f'Classification report (TEST):\\n{classification_report(y_test, y_pred_te, digits=4, zero_division=0)}')\n",
    "\n",
    "        results_rows.append({\n",
    "            'model': name,\n",
    "            'accuracy_train': acc_tr, 'roc_auc_train': roc_tr, 'eer_train': eer_tr,\n",
    "            'far_at_eer_train': far_tr, 'frr_at_eer_train': frr_tr,\n",
    "            'accuracy': acc_te, 'roc_auc': roc_te, 'eer': eer_te,\n",
    "            'far_at_eer': far_te, 'frr_at_eer': frr_te\n",
    "        })\n",
    "\n",
    "    for name, clf in model_dict.items():\n",
    "        evaluate_model(name, clf)\n",
    "\n",
    "    # GMM evaluation\n",
    "    ll_real_train = gmm_real.score_samples(X_train_sc)\n",
    "    ll_fake_train = gmm_fake.score_samples(X_train_sc)\n",
    "    gmm_scores_train = ll_fake_train - ll_real_train\n",
    "\n",
    "    ll_real_test = gmm_real.score_samples(X_test_sc)\n",
    "    ll_fake_test = gmm_fake.score_samples(X_test_sc)\n",
    "    gmm_scores_test = ll_fake_test - ll_real_test\n",
    "\n",
    "    eer_tr, thr_tr, _, _ = compute_eer_and_curve(y_train, gmm_scores_train)\n",
    "    far_tr, frr_tr = far_frr_at_threshold(y_train, gmm_scores_train, thr_tr)\n",
    "    y_pred_tr = (gmm_scores_train >= thr_tr).astype(int)\n",
    "    acc_tr = accuracy_score(y_train, y_pred_tr)\n",
    "    roc_tr = roc_auc_score(y_train, gmm_scores_train)\n",
    "\n",
    "    eer_te, thr_te, _, _ = compute_eer_and_curve(y_test, gmm_scores_test)\n",
    "    far_te, frr_te = far_frr_at_threshold(y_test, gmm_scores_test, thr_te)\n",
    "    y_pred_te = (gmm_scores_test >= thr_te).astype(int)\n",
    "    acc_te = accuracy_score(y_test, y_pred_te)\n",
    "    roc_te = roc_auc_score(y_test, gmm_scores_test)\n",
    "\n",
    "    print(f'\\n== GMM_logL_diff ({tag}) ==')\n",
    "    print(f'[TRAIN] Acc: {acc_tr:.4f} | AUC: {roc_tr:.4f} | EER: {eer_tr*100:.2f}%')\n",
    "    print(f'[TEST]  Acc: {acc_te:.4f} | AUC: {roc_te:.4f} | EER: {eer_te*100:.2f}%')\n",
    "    print(f'Classification report (TEST):\\n{classification_report(y_test, y_pred_te, digits=4, zero_division=0)}')\n",
    "\n",
    "    results_rows.append({\n",
    "        'model': 'GMM_logL_diff',\n",
    "        'accuracy_train': acc_tr, 'roc_auc_train': roc_tr, 'eer_train': eer_tr,\n",
    "        'far_at_eer_train': far_tr, 'frr_at_eer_train': frr_tr,\n",
    "        'accuracy': acc_te, 'roc_auc': roc_te, 'eer': eer_te,\n",
    "        'far_at_eer': far_te, 'frr_at_eer': frr_te\n",
    "    })\n",
    "\n",
    "    results_df = pd.DataFrame(results_rows).sort_values('roc_auc', ascending=False)\n",
    "    print(f'\\n=== Summary metrics (sorted by TEST ROC-AUC) for {tag} ===')\n",
    "    print(results_df)\n",
    "\n",
    "    # FAR vs FRR plot for best model\n",
    "    best_name = results_df.iloc[0]['model']\n",
    "    if best_name == 'GMM_logL_diff':\n",
    "        scores_best = gmm_scores_test\n",
    "    else:\n",
    "        best_clf = model_dict[best_name]\n",
    "        if hasattr(best_clf, 'predict_proba'):\n",
    "            scores_best = best_clf.predict_proba(X_test_sc)[:, 1]\n",
    "        else:\n",
    "            scores_best = best_clf.decision_function(X_test_sc)\n",
    "\n",
    "    _, _, fpr_best, fnr_best = compute_eer_and_curve(y_test, scores_best)\n",
    "    fig, ax = plt.subplots(figsize=(6, 5))\n",
    "    ax.plot(fpr_best, fnr_best, label=f'{best_name} ({tag})')\n",
    "    ax.plot([0, 1], [1, 0], '--', linewidth=1)\n",
    "    ax.set_xlabel('FAR')\n",
    "    ax.set_ylabel('FRR')\n",
    "    ax.set_title(f'FAR vs FRR ({best_name}, {tag})')\n",
    "    ax.legend()\n",
    "    ax.grid(alpha=0.3)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(os.path.expanduser(f'~/Downloads/far_frr_{tag}.png'), bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    return {\n",
    "        'tag': tag,\n",
    "        'metrics': results_df,\n",
    "        'features_used': used_features,\n",
    "        'model_dict': model_dict,\n",
    "        'gmm_real': gmm_real,\n",
    "        'gmm_fake': gmm_fake,\n",
    "        'X_test_sc': X_test_sc,\n",
    "        'y_test': y_test,\n",
    "    }\n",
    "\n",
    "# Run models for both conditions\n",
    "res_44k = run_models(df_all_44k, anova_44k, '44k_25ms')\n",
    "res_16k = run_models(df_all_16k, anova_16k, '16k_fullclip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T18:25:22.015782Z",
     "iopub.status.busy": "2026-02-14T18:25:22.015662Z",
     "iopub.status.idle": "2026-02-14T18:41:35.022062Z",
     "shell.execute_reply": "2026-02-14T18:41:35.021762Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ McNemar tests for 44k_25ms ================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x110f31bc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x1121f5bc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x109d09bc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x109d35bc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x110c71bc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x106971bc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x107ef5bc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x102955bc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x104bc5bc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x105871bc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== McNemar (TRAIN) for 44k_25ms ===\n",
      "GMM_logL_diff vs GaussianNB | b=3875, c=4575 | chi2=57.8226 | p=2.869e-14 -> Significant\n",
      "GMM_logL_diff vs LDA | b=3735, c=4160 | chi2=22.7709 | p=1.825e-06 -> Significant\n",
      "GMM_logL_diff vs LogisticRegression | b=3710, c=4034 | chi2=13.4722 | p=0.0002421 -> Significant\n",
      "GMM_logL_diff vs QDA | b=3654, c=3629 | chi2=0.0791 | p=0.7785 -> Not significant\n",
      "GMM_logL_diff vs SVM_linear | b=3579, c=3782 | chi2=5.5433 | p=0.01855 -> Significant\n",
      "GMM_logL_diff vs SVM_rbf | b=5207, c=1374 | chi2=2231.3059 | p=0 -> Significant\n",
      "GaussianNB vs LDA | b=2196, c=1921 | chi2=18.2356 | p=1.952e-05 -> Significant\n",
      "GaussianNB vs LogisticRegression | b=2310, c=1934 | chi2=33.1350 | p=8.598e-09 -> Significant\n",
      "GaussianNB vs QDA | b=2219, c=1494 | chi2=141.1732 | p=1.475e-32 -> Significant\n",
      "GaussianNB vs SVM_linear | b=2333, c=1836 | chi2=59.0108 | p=1.568e-14 -> Significant\n",
      "GaussianNB vs SVM_rbf | b=5638, c=1105 | chi2=3045.9772 | p=0 -> Significant\n",
      "LDA vs LogisticRegression | b=1090, c=989 | chi2=4.8100 | p=0.02829 -> Significant\n",
      "LDA vs QDA | b=2227, c=1777 | chi2=50.3499 | p=1.286e-12 -> Significant\n",
      "LDA vs SVM_linear | b=979, c=757 | chi2=28.1342 | p=1.132e-07 -> Significant\n",
      "LDA vs SVM_rbf | b=5314, c=1056 | chi2=2844.9057 | p=0 -> Significant\n",
      "LogisticRegression vs QDA | b=2188, c=1839 | chi2=30.0730 | p=4.161e-08 -> Significant\n",
      "LogisticRegression vs SVM_linear | b=621, c=500 | chi2=12.8457 | p=0.0003383 -> Significant\n",
      "LogisticRegression vs SVM_rbf | b=5222, c=1065 | chi2=2747.3097 | p=0 -> Significant\n",
      "QDA vs SVM_linear | b=1634, c=1862 | chi2=14.7394 | p=0.0001234 -> Significant\n",
      "QDA vs SVM_rbf | b=4850, c=1042 | chi2=2459.8182 | p=0 -> Significant\n",
      "SVM_linear vs SVM_rbf | b=5097, c=1061 | chi2=2643.9144 | p=0 -> Significant\n",
      "\n",
      "=== McNemar (TEST) for 44k_25ms ===\n",
      "GMM_logL_diff vs GaussianNB | b=1016, c=1199 | chi2=14.9544 | p=0.0001101 -> Significant\n",
      "GMM_logL_diff vs LDA | b=958, c=1080 | chi2=7.1840 | p=0.007356 -> Significant\n",
      "GMM_logL_diff vs LogisticRegression | b=955, c=1031 | chi2=2.8323 | p=0.09238 -> Not significant\n",
      "GMM_logL_diff vs QDA | b=924, c=894 | chi2=0.4626 | p=0.4964 -> Not significant\n",
      "GMM_logL_diff vs SVM_linear | b=921, c=973 | chi2=1.3733 | p=0.2412 -> Not significant\n",
      "GMM_logL_diff vs SVM_rbf | b=1221, c=405 | chi2=408.5025 | p=7.764e-91 -> Significant\n",
      "GaussianNB vs LDA | b=557, c=496 | chi2=3.4188 | p=0.06446 -> Not significant\n",
      "GaussianNB vs LogisticRegression | b=586, c=479 | chi2=10.5502 | p=0.001162 -> Significant\n",
      "GaussianNB vs QDA | b=592, c=379 | chi2=46.2863 | p=1.022e-11 -> Significant\n",
      "GaussianNB vs SVM_linear | b=581, c=450 | chi2=16.3919 | p=5.151e-05 -> Significant\n",
      "GaussianNB vs SVM_rbf | b=1354, c=355 | chi2=582.7993 | p=9.23e-129 -> Significant\n",
      "LDA vs LogisticRegression | b=256, c=210 | chi2=4.3455 | p=0.03711 -> Significant\n",
      "LDA vs QDA | b=582, c=430 | chi2=22.5306 | p=2.068e-06 -> Significant\n",
      "LDA vs SVM_linear | b=238, c=168 | chi2=11.7266 | p=0.0006161 -> Significant\n",
      "LDA vs SVM_rbf | b=1265, c=327 | chi2=551.4881 | p=5.974e-122 -> Significant\n",
      "LogisticRegression vs QDA | b=564, c=458 | chi2=10.7877 | p=0.001022 -> Significant\n",
      "LogisticRegression vs SVM_linear | b=148, c=124 | chi2=1.9449 | p=0.1631 -> Not significant\n",
      "LogisticRegression vs SVM_rbf | b=1228, c=336 | chi2=507.5965 | p=2.114e-112 -> Significant\n",
      "QDA vs SVM_linear | b=404, c=486 | chi2=7.3719 | p=0.006625 -> Significant\n",
      "QDA vs SVM_rbf | b=1116, c=330 | chi2=426.1584 | p=1.114e-94 -> Significant\n",
      "SVM_linear vs SVM_rbf | b=1201, c=333 | chi2=490.0189 | p=1.412e-108 -> Significant\n",
      "\n",
      "================ McNemar tests for 16k_fullclip ================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x110a71bc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x1069a9bc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== McNemar (TRAIN) for 16k_fullclip ===\n",
      "GMM_logL_diff vs GaussianNB | b=2228, c=3448 | chi2=261.7972 | p=6.963e-59 -> Significant\n",
      "GMM_logL_diff vs LDA | b=2006, c=3055 | chi2=217.0132 | p=4.054e-49 -> Significant\n",
      "GMM_logL_diff vs LogisticRegression | b=1980, c=2980 | chi2=201.2099 | p=1.137e-45 -> Significant\n",
      "GMM_logL_diff vs QDA | b=1690, c=2298 | chi2=92.3894 | p=7.119e-22 -> Significant\n",
      "GMM_logL_diff vs SVM_linear | b=1786, c=2696 | chi2=184.3554 | p=5.426e-42 -> Significant\n",
      "GMM_logL_diff vs SVM_rbf | b=4318, c=1308 | chi2=1609.3283 | p=0 -> Significant\n",
      "GaussianNB vs LDA | b=1833, c=1662 | chi2=8.2690 | p=0.004033 -> Significant\n",
      "GaussianNB vs LogisticRegression | b=1875, c=1655 | chi2=13.5867 | p=0.0002278 -> Significant\n",
      "GaussianNB vs QDA | b=2000, c=1388 | chi2=110.1892 | p=8.907e-26 -> Significant\n",
      "GaussianNB vs SVM_linear | b=1907, c=1597 | chi2=27.2491 | p=1.789e-07 -> Significant\n",
      "GaussianNB vs SVM_rbf | b=5508, c=1278 | chi2=2635.4909 | p=0 -> Significant\n",
      "LDA vs LogisticRegression | b=713, c=664 | chi2=1.6732 | p=0.1958 -> Not significant\n",
      "LDA vs QDA | b=2185, c=1744 | chi2=49.2746 | p=2.225e-12 -> Significant\n",
      "LDA vs SVM_linear | b=798, c=659 | chi2=13.0707 | p=0.0003 -> Significant\n",
      "LDA vs SVM_rbf | b=5335, c=1276 | chi2=2490.9036 | p=0 -> Significant\n",
      "LogisticRegression vs QDA | b=2042, c=1650 | chi2=41.4087 | p=1.235e-10 -> Significant\n",
      "LogisticRegression vs SVM_linear | b=571, c=481 | chi2=7.5295 | p=0.00607 -> Significant\n",
      "LogisticRegression vs SVM_rbf | b=5257, c=1247 | chi2=2471.1072 | p=0 -> Significant\n",
      "QDA vs SVM_linear | b=1539, c=1841 | chi2=26.8050 | p=2.251e-07 -> Significant\n",
      "QDA vs SVM_rbf | b=4875, c=1257 | chi2=2133.5109 | p=0 -> Significant\n",
      "SVM_linear vs SVM_rbf | b=5164, c=1244 | chi2=2396.7792 | p=0 -> Significant\n",
      "\n",
      "=== McNemar (TEST) for 16k_fullclip ===\n",
      "GMM_logL_diff vs GaussianNB | b=572, c=792 | chi2=35.1620 | p=3.034e-09 -> Significant\n",
      "GMM_logL_diff vs LDA | b=513, c=729 | chi2=37.2182 | p=1.056e-09 -> Significant\n",
      "GMM_logL_diff vs LogisticRegression | b=508, c=716 | chi2=35.0074 | p=3.285e-09 -> Significant\n",
      "GMM_logL_diff vs QDA | b=456, c=521 | chi2=4.1924 | p=0.0406 -> Significant\n",
      "GMM_logL_diff vs SVM_linear | b=469, c=631 | chi2=23.5645 | p=1.208e-06 -> Significant\n",
      "GMM_logL_diff vs SVM_rbf | b=1072, c=374 | chi2=335.9675 | p=4.821e-75 -> Significant\n",
      "GaussianNB vs LDA | b=437, c=433 | chi2=0.0103 | p=0.919 -> Not significant\n",
      "GaussianNB vs LogisticRegression | b=461, c=449 | chi2=0.1330 | p=0.7154 -> Not significant\n",
      "GaussianNB vs QDA | b=481, c=326 | chi2=29.3879 | p=5.925e-08 -> Significant\n",
      "GaussianNB vs SVM_linear | b=481, c=423 | chi2=3.5940 | p=0.05799 -> Not significant\n",
      "GaussianNB vs SVM_rbf | b=1325, c=407 | chi2=485.5017 | p=1.357e-107 -> Significant\n",
      "LDA vs LogisticRegression | b=164, c=156 | chi2=0.1531 | p=0.6956 -> Not significant\n",
      "LDA vs QDA | b=544, c=393 | chi2=24.0128 | p=9.57e-07 -> Significant\n",
      "LDA vs SVM_linear | b=192, c=138 | chi2=8.5121 | p=0.003528 -> Significant\n",
      "LDA vs SVM_rbf | b=1299, c=385 | chi2=494.9935 | p=1.168e-109 -> Significant\n",
      "LogisticRegression vs QDA | b=536, c=393 | chi2=21.7051 | p=3.18e-06 -> Significant\n",
      "LogisticRegression vs SVM_linear | b=150, c=104 | chi2=7.9724 | p=0.004749 -> Significant\n",
      "LogisticRegression vs SVM_rbf | b=1279, c=373 | chi2=495.7778 | p=7.882e-110 -> Significant\n",
      "QDA vs SVM_linear | b=379, c=476 | chi2=10.7789 | p=0.001027 -> Significant\n",
      "QDA vs SVM_rbf | b=1151, c=388 | chi2=377.2865 | p=4.85e-84 -> Significant\n",
      "SVM_linear vs SVM_rbf | b=1233, c=373 | chi2=459.4527 | p=6.324e-102 -> Significant\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# 6) McNemar's Pairwise Statistical Tests\n",
    "# =========================================\n",
    "\n",
    "def run_mcnemar_all(df_all, anova_df, tag):\n",
    "    print(f'\\n================ McNemar tests for {tag} ================')\n",
    "\n",
    "    sig_level = 0.05\n",
    "    weak_features_stat = anova_df.loc[anova_df['p_value'] >= sig_level, 'feature'].tolist()\n",
    "    all_nan_cols = [c for c in df_all.columns if df_all[c].isna().all()]\n",
    "    drop_cols = list(set(['label','path','group','sr_tag'] + weak_features_stat + all_nan_cols))\n",
    "\n",
    "    X = df_all.drop(columns=[c for c in drop_cols if c in df_all.columns]) \\\n",
    "             .select_dtypes(include=[np.number]).copy()\n",
    "    y = df_all['label'].astype(int).to_numpy()\n",
    "    X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    all_nan_cols2 = X.columns[X.isna().all()].tolist()\n",
    "    if all_nan_cols2:\n",
    "        X.drop(columns=all_nan_cols2, inplace=True)\n",
    "\n",
    "    if 'group' in df_all.columns:\n",
    "        gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=SEED)\n",
    "        tr_idx, te_idx = next(gss.split(X, y, groups=df_all['group'].to_numpy()))\n",
    "    else:\n",
    "        tr_idx, te_idx = train_test_split(\n",
    "            np.arange(len(y)), test_size=0.2, stratify=y, random_state=SEED\n",
    "        )\n",
    "\n",
    "    X_train, X_test = X.iloc[tr_idx], X.iloc[te_idx]\n",
    "    y_train, y_test = y[tr_idx], y[te_idx]\n",
    "\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    scaler = StandardScaler()\n",
    "    X_train_sc = scaler.fit_transform(imputer.fit_transform(X_train))\n",
    "    X_test_sc = scaler.transform(imputer.transform(X_test))\n",
    "\n",
    "    model_dict = {\n",
    "        'LogisticRegression': LogisticRegression(max_iter=1000, class_weight='balanced', random_state=SEED),\n",
    "        'LDA': LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto'),\n",
    "        'QDA': QuadraticDiscriminantAnalysis(reg_param=1e-3),\n",
    "        'GaussianNB': GaussianNB(),\n",
    "        'SVM_linear': SVC(kernel='linear', C=1.0, class_weight='balanced', random_state=SEED, probability=True),\n",
    "    }\n",
    "\n",
    "    grid = GridSearchCV(\n",
    "        SVC(kernel='rbf', class_weight='balanced', random_state=SEED, probability=True),\n",
    "        {'C': [0.1, 1, 10], 'gamma': ['scale', 0.01, 0.001]},\n",
    "        cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=SEED),\n",
    "        scoring='roc_auc', n_jobs=-1\n",
    "    )\n",
    "    grid.fit(X_train_sc, y_train)\n",
    "    model_dict['SVM_rbf'] = grid.best_estimator_\n",
    "\n",
    "    gmm_real = GaussianMixture(n_components=3, covariance_type='full', random_state=SEED)\n",
    "    gmm_fake = GaussianMixture(n_components=3, covariance_type='full', random_state=SEED + 1)\n",
    "    gmm_real.fit(X_train_sc[y_train == 0])\n",
    "    gmm_fake.fit(X_train_sc[y_train == 1])\n",
    "\n",
    "    preds_train, preds_test = {}, {}\n",
    "\n",
    "    for name, clf in model_dict.items():\n",
    "        clf.fit(X_train_sc, y_train)\n",
    "        if hasattr(clf, 'predict_proba'):\n",
    "            s_tr = clf.predict_proba(X_train_sc)[:, 1]\n",
    "            s_te = clf.predict_proba(X_test_sc)[:, 1]\n",
    "        else:\n",
    "            s_tr = clf.decision_function(X_train_sc)\n",
    "            s_te = clf.decision_function(X_test_sc)\n",
    "        _, thr_tr, _, _ = compute_eer_and_curve(y_train, s_tr)\n",
    "        _, thr_te, _, _ = compute_eer_and_curve(y_test, s_te)\n",
    "        preds_train[name] = (s_tr >= thr_tr).astype(int)\n",
    "        preds_test[name] = (s_te >= thr_te).astype(int)\n",
    "\n",
    "    # GMM\n",
    "    s_tr_gmm = gmm_fake.score_samples(X_train_sc) - gmm_real.score_samples(X_train_sc)\n",
    "    s_te_gmm = gmm_fake.score_samples(X_test_sc) - gmm_real.score_samples(X_test_sc)\n",
    "    _, thr_tr_gmm, _, _ = compute_eer_and_curve(y_train, s_tr_gmm)\n",
    "    _, thr_te_gmm, _, _ = compute_eer_and_curve(y_test, s_te_gmm)\n",
    "    preds_train['GMM_logL_diff'] = (s_tr_gmm >= thr_tr_gmm).astype(int)\n",
    "    preds_test['GMM_logL_diff'] = (s_te_gmm >= thr_te_gmm).astype(int)\n",
    "\n",
    "    def mcnemar_for_predictions(y_true, preds_dict, which_split):\n",
    "        model_names = sorted(preds_dict.keys())\n",
    "        rows = []\n",
    "        print(f'\\n=== McNemar ({which_split}) for {tag} ===')\n",
    "        for m1, m2 in combinations(model_names, 2):\n",
    "            correct1 = (preds_dict[m1] == y_true)\n",
    "            correct2 = (preds_dict[m2] == y_true)\n",
    "            b = np.sum((correct1 == 0) & (correct2 == 1))\n",
    "            c = np.sum((correct1 == 1) & (correct2 == 0))\n",
    "            if b + c == 0:\n",
    "                chi2_stat, p_value = 0.0, 1.0\n",
    "            else:\n",
    "                chi2_stat = (abs(b - c) - 1)**2 / (b + c)\n",
    "                p_value = chi2.sf(chi2_stat, df=1)\n",
    "            signif = 'Significant' if p_value < 0.05 else 'Not significant'\n",
    "            print(f'{m1} vs {m2} | b={b}, c={c} | chi2={chi2_stat:.4f} | p={p_value:.4g} -> {signif}')\n",
    "            rows.append({'model_1': m1, 'model_2': m2, 'b': int(b), 'c': int(c),\n",
    "                         'chi2': chi2_stat, 'p_value': p_value, 'significant': p_value < 0.05})\n",
    "        return pd.DataFrame(rows)\n",
    "\n",
    "    df_mcn_train = mcnemar_for_predictions(y_train, preds_train, 'TRAIN')\n",
    "    df_mcn_test = mcnemar_for_predictions(y_test, preds_test, 'TEST')\n",
    "    return df_mcn_train, df_mcn_test\n",
    "\n",
    "mcn_train_44k, mcn_test_44k = run_mcnemar_all(df_all_44k, anova_44k, '44k_25ms')\n",
    "mcn_train_16k, mcn_test_16k = run_mcnemar_all(df_all_16k, anova_16k, '16k_fullclip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T18:41:35.023516Z",
     "iopub.status.busy": "2026-02-14T18:41:35.023426Z",
     "iopub.status.idle": "2026-02-14T18:41:35.143898Z",
     "shell.execute_reply": "2026-02-14T18:41:35.143669Z"
    }
   },
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# 7) Train vs Test Accuracy Bar Charts\n",
    "# =========================================\n",
    "\n",
    "def plot_train_test_accuracy(metrics_df, tag):\n",
    "    order = ['SVM_rbf', 'GMM_logL_diff', 'QDA', 'SVM_linear',\n",
    "             'LogisticRegression', 'LDA', 'GaussianNB']\n",
    "    metrics_df = metrics_df.set_index('model').loc[\n",
    "        [m for m in order if m in metrics_df['model'].values]\n",
    "    ].reset_index()\n",
    "\n",
    "    pretty_names = {\n",
    "        'LogisticRegression': 'Logistic Regression', 'LDA': 'LDA',\n",
    "        'QDA': 'QDA', 'GaussianNB': 'Gaussian NB',\n",
    "        'SVM_linear': 'Linear SVM', 'SVM_rbf': 'RBF SVM',\n",
    "        'GMM_logL_diff': 'GMM',\n",
    "    }\n",
    "\n",
    "    model_names = [pretty_names.get(m, m) for m in metrics_df['model']]\n",
    "    train_accs = metrics_df['accuracy_train'].to_numpy()\n",
    "    test_accs = metrics_df['accuracy'].to_numpy()\n",
    "\n",
    "    x = np.arange(len(model_names))\n",
    "    width = 0.35\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.bar(x - width/2, train_accs, width, label='Train Accuracy')\n",
    "    ax.bar(x + width/2, test_accs, width, label='Test Accuracy')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(model_names, rotation=45)\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.set_ylim(0.5, 1.0)\n",
    "    ax.set_title(f'Train vs Test Accuracy ({tag})')\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(os.path.expanduser(f'~/Downloads/accuracy_bar_{tag}.png'), bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "plot_train_test_accuracy(res_16k['metrics'].copy(), '16k_fullclip')\n",
    "plot_train_test_accuracy(res_44k['metrics'].copy(), '44k_25ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T18:41:35.145057Z",
     "iopub.status.busy": "2026-02-14T18:41:35.144962Z",
     "iopub.status.idle": "2026-02-14T18:58:48.463538Z",
     "shell.execute_reply": "2026-02-14T18:58:48.444124Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning RBF SVM for ROC...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x106471bc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning RBF SVM for ROC...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x107b71bc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x108375bc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x102b71bc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x109971bc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x104431bc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x103371bc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x105b71bc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x104495bc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x107871bc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x104d71bc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# 8) ROC Curves for All Models\n",
    "# =========================================\n",
    "\n",
    "def prepare_features_for_roc(df_all, anova_df, tag, sig_level=0.05):\n",
    "    weak_features = anova_df.loc[anova_df['p_value'] >= sig_level, 'feature'].tolist()\n",
    "    all_nan_cols = [c for c in df_all.columns if df_all[c].isna().all()]\n",
    "    drop_cols = list(set(['label','path','group','sr_tag'] + weak_features + all_nan_cols))\n",
    "    X = df_all.drop(columns=[c for c in drop_cols if c in df_all.columns]) \\\n",
    "              .select_dtypes(include=[np.number]).copy()\n",
    "    y = df_all['label'].astype(int).to_numpy()\n",
    "    X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    nan2 = X.columns[X.isna().all()].tolist()\n",
    "    if nan2: X.drop(columns=nan2, inplace=True)\n",
    "\n",
    "    if 'group' in df_all.columns:\n",
    "        gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=SEED)\n",
    "        tr_idx, te_idx = next(gss.split(X, y, groups=df_all['group'].to_numpy()))\n",
    "    else:\n",
    "        tr_idx, te_idx = train_test_split(np.arange(len(y)), test_size=0.2, stratify=y, random_state=SEED)\n",
    "\n",
    "    X_train, X_test = X.iloc[tr_idx], X.iloc[te_idx]\n",
    "    y_train, y_test = y[tr_idx], y[te_idx]\n",
    "\n",
    "    imp = SimpleImputer(strategy='median')\n",
    "    sc = StandardScaler()\n",
    "    X_train_sc = sc.fit_transform(imp.fit_transform(X_train))\n",
    "    X_test_sc = sc.transform(imp.transform(X_test))\n",
    "    return X_train_sc, X_test_sc, y_train, y_test\n",
    "\n",
    "def fit_all_models_get_scores(X_train_sc, X_test_sc, y_train, y_test):\n",
    "    model_dict = {\n",
    "        'LogisticRegression': LogisticRegression(max_iter=1000, class_weight='balanced', random_state=SEED),\n",
    "        'LDA': LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto'),\n",
    "        'QDA': QuadraticDiscriminantAnalysis(reg_param=1e-3),\n",
    "        'GaussianNB': GaussianNB(),\n",
    "        'SVM_linear': SVC(kernel='linear', C=1.0, class_weight='balanced', random_state=SEED, probability=True),\n",
    "    }\n",
    "    grid = GridSearchCV(\n",
    "        SVC(kernel='rbf', class_weight='balanced', random_state=SEED, probability=True),\n",
    "        {'C': [0.1, 1, 10], 'gamma': ['scale', 0.01, 0.001]},\n",
    "        cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=SEED),\n",
    "        scoring='roc_auc', n_jobs=-1\n",
    "    )\n",
    "    print('Tuning RBF SVM for ROC...')\n",
    "    grid.fit(X_train_sc, y_train)\n",
    "    model_dict['SVM_rbf'] = grid.best_estimator_\n",
    "\n",
    "    scores_dict = {}\n",
    "    for name, clf in model_dict.items():\n",
    "        clf.fit(X_train_sc, y_train)\n",
    "        if hasattr(clf, 'predict_proba'):\n",
    "            scores_dict[name] = clf.predict_proba(X_test_sc)[:, 1]\n",
    "        else:\n",
    "            scores_dict[name] = clf.decision_function(X_test_sc)\n",
    "\n",
    "    gmm_real = GaussianMixture(n_components=3, covariance_type='full', random_state=SEED)\n",
    "    gmm_fake = GaussianMixture(n_components=3, covariance_type='full', random_state=SEED + 1)\n",
    "    gmm_real.fit(X_train_sc[y_train == 0])\n",
    "    gmm_fake.fit(X_train_sc[y_train == 1])\n",
    "    scores_dict['GMM_logL_diff'] = gmm_fake.score_samples(X_test_sc) - gmm_real.score_samples(X_test_sc)\n",
    "    return scores_dict\n",
    "\n",
    "def plot_roc_all_models(y_test, scores_dict, title_suffix):\n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "    for name, scores in scores_dict.items():\n",
    "        fpr, tpr, _ = roc_curve(y_test, scores)\n",
    "        auc_val = roc_auc_score(y_test, scores)\n",
    "        ax.plot(fpr, tpr, label=f'{name} (AUC = {auc_val:.2f})')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', label='Baseline (AUC = 0.50)')\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_title(f'ROC Curves - {title_suffix}')\n",
    "    ax.grid(True, linestyle='--', linewidth=0.5)\n",
    "    ax.legend(fontsize=8, loc='lower right')\n",
    "    fig.tight_layout()\n",
    "    safe_name = title_suffix.replace(' ', '_').replace(',', '')\n",
    "    fig.savefig(os.path.expanduser(f'~/Downloads/roc_{safe_name}.png'), bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# 44.1 kHz ROC\n",
    "Xtr_44, Xte_44, ytr_44, yte_44 = prepare_features_for_roc(df_all_44k, anova_44k, '44k_25ms')\n",
    "scores_44 = fit_all_models_get_scores(Xtr_44, Xte_44, ytr_44, yte_44)\n",
    "plot_roc_all_models(yte_44, scores_44, 'FoR 44.1 kHz 25ms window')\n",
    "\n",
    "# 16 kHz ROC\n",
    "Xtr_16, Xte_16, ytr_16, yte_16 = prepare_features_for_roc(df_all_16k, anova_16k, '16k_fullclip')\n",
    "scores_16 = fit_all_models_get_scores(Xtr_16, Xte_16, ytr_16, yte_16)\n",
    "plot_roc_all_models(yte_16, scores_16, 'FoR 16 kHz full clip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T18:58:48.483810Z",
     "iopub.status.busy": "2026-02-14T18:58:48.483631Z",
     "iopub.status.idle": "2026-02-14T18:58:48.817985Z",
     "shell.execute_reply": "2026-02-14T18:58:48.817659Z"
    }
   },
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# 9) DET Curves\n",
    "# =========================================\n",
    "\n",
    "def plot_det_all_models(y_test, scores_dict, title_suffix):\n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "    ticks = np.array([0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1, 0.2, 0.5])\n",
    "    tick_labels = [f'{int(t * 100)}%' for t in ticks]\n",
    "\n",
    "    for name, scores in scores_dict.items():\n",
    "        fpr_det, fnr_det, _ = det_curve(y_test, scores)\n",
    "        eps = 1e-6\n",
    "        fpr_det = np.clip(fpr_det, ticks[0] + eps, 0.5 - eps)\n",
    "        fnr_det = np.clip(fnr_det, ticks[0] + eps, 0.5 - eps)\n",
    "        ax.plot(fpr_det, fnr_det, label=name)\n",
    "\n",
    "    xx = np.linspace(ticks[0], 0.5, 400)\n",
    "    yy = np.clip(1.0 - xx, ticks[0], 0.5)\n",
    "    ax.plot(xx, yy, 'k--', label='Baseline')\n",
    "\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xticks(ticks)\n",
    "    ax.set_xticklabels(tick_labels)\n",
    "    ax.set_yticks(ticks)\n",
    "    ax.set_yticklabels(tick_labels)\n",
    "    ax.set_xlim([ticks[0], 0.5])\n",
    "    ax.set_ylim([ticks[0], 0.5])\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('False Negative Rate')\n",
    "    ax.set_title(f'DET Curves - {title_suffix}')\n",
    "    ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "    ax.legend(fontsize=8, loc='lower left')\n",
    "    fig.tight_layout()\n",
    "    safe_name = title_suffix.replace(' ', '_').replace(',', '')\n",
    "    fig.savefig(os.path.expanduser(f'~/Downloads/det_{safe_name}.png'), bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "plot_det_all_models(yte_44, scores_44, 'FoR 44.1 kHz 25ms window')\n",
    "plot_det_all_models(yte_16, scores_16, 'FoR 16 kHz full clip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T18:58:48.819395Z",
     "iopub.status.busy": "2026-02-14T18:58:48.819262Z",
     "iopub.status.idle": "2026-02-14T18:58:50.094385Z",
     "shell.execute_reply": "2026-02-14T18:58:50.094080Z"
    }
   },
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# 10) Correlation Heatmaps (Real vs Fake)\n",
    "# =========================================\n",
    "\n",
    "def plot_corr_heatmaps_real_fake(df_all, feature_list, tag):\n",
    "    cols = [c for c in feature_list\n",
    "            if c in df_all.columns and np.issubdtype(df_all[c].dtype, np.number)]\n",
    "    if not cols:\n",
    "        print(f'No numeric features to plot for {tag}.')\n",
    "        return\n",
    "\n",
    "    df_real = df_all[df_all['label'] == 0][cols].dropna(axis=1, how='all')\n",
    "    df_fake = df_all[df_all['label'] == 1][cols].dropna(axis=1, how='all')\n",
    "\n",
    "    common_cols = sorted(set(df_real.columns).intersection(set(df_fake.columns)))\n",
    "    if not common_cols:\n",
    "        print(f'No common features for {tag}.')\n",
    "        return\n",
    "\n",
    "    corr_real = df_real[common_cols].corr()\n",
    "    corr_fake = df_fake[common_cols].corr()\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n",
    "    fig.suptitle(f'Feature Correlation Heatmaps (Real vs Fake) - {tag}', fontsize=14)\n",
    "\n",
    "    for ax, corr, title in zip(axes, [corr_real, corr_fake], ['REAL', 'FAKE']):\n",
    "        im = ax.imshow(corr.values, vmin=-1, vmax=1, cmap='coolwarm')\n",
    "        ax.set_title(title)\n",
    "        ax.set_xticks(np.arange(len(corr.columns)))\n",
    "        ax.set_yticks(np.arange(len(corr.columns)))\n",
    "        ax.set_xticklabels(corr.columns, rotation=90)\n",
    "        ax.set_yticklabels(corr.columns)\n",
    "        for i in range(corr.shape[0]):\n",
    "            for j in range(corr.shape[1]):\n",
    "                ax.text(j, i, f'{corr.values[i, j]:.2f}',\n",
    "                        ha='center', va='center', fontsize=6, color='black')\n",
    "\n",
    "    cbar_ax = fig.add_axes([0.47, 0.15, 0.02, 0.7])\n",
    "    fig.colorbar(im, cax=cbar_ax)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    fig.savefig(os.path.expanduser(f'~/Downloads/corr_heatmap_{tag}.png'), bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "plot_corr_heatmaps_real_fake(df_all_44k, res_44k['features_used'], '44k_25ms')\n",
    "plot_corr_heatmaps_real_fake(df_all_16k, res_16k['features_used'], '16k_fullclip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T18:58:50.095993Z",
     "iopub.status.busy": "2026-02-14T18:58:50.095876Z",
     "iopub.status.idle": "2026-02-14T18:58:50.150791Z",
     "shell.execute_reply": "2026-02-14T18:58:50.150501Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SIDE-BY-SIDE COMPARISON (16k vs 44k) ===\n",
      "                    accuracy_train_16k  roc_auc_train_16k  eer_train_16k  \\\n",
      "model                                                                      \n",
      "GMM_logL_diff                 0.744270           0.817544       0.255730   \n",
      "GaussianNB                    0.695300           0.762349       0.304701   \n",
      "LDA                           0.702164           0.765703       0.297836   \n",
      "LogisticRegression            0.704130           0.768584       0.295870   \n",
      "QDA                           0.719865           0.789904       0.280135   \n",
      "SVM_linear                    0.707743           0.765938       0.292257   \n",
      "SVM_rbf                       0.865091           0.936007       0.134910   \n",
      "\n",
      "                    far_at_eer_train_16k  frr_at_eer_train_16k  accuracy_16k  \\\n",
      "model                                                                          \n",
      "GMM_logL_diff                   0.255643              0.255816      0.731084   \n",
      "GaussianNB                      0.304740              0.304661      0.695743   \n",
      "LDA                             0.297807              0.297866      0.696386   \n",
      "LogisticRegression              0.295872              0.295867      0.697671   \n",
      "QDA                             0.280152              0.280118      0.720643   \n",
      "SVM_linear                      0.292244              0.292270      0.705060   \n",
      "SVM_rbf                         0.134956              0.134863      0.843213   \n",
      "\n",
      "                    roc_auc_16k   eer_16k  far_at_eer_16k  frr_at_eer_16k  \\\n",
      "model                                                                       \n",
      "GMM_logL_diff          0.807356  0.268917        0.268766        0.269068   \n",
      "GaussianNB             0.761462  0.304259        0.304071        0.304447   \n",
      "LDA                    0.760262  0.303613        0.303753        0.303473   \n",
      "LogisticRegression     0.763577  0.302328        0.302481        0.302175   \n",
      "QDA                    0.790225  0.279358        0.279262        0.279455   \n",
      "SVM_linear             0.757861  0.294937        0.295165        0.294710   \n",
      "SVM_rbf                0.921729  0.156787        0.156807        0.156767   \n",
      "\n",
      "                    accuracy_train_44k  roc_auc_train_44k  eer_train_44k  \\\n",
      "model                                                                      \n",
      "GMM_logL_diff                 0.724722           0.810066       0.275278   \n",
      "GaussianNB                    0.696624           0.765210       0.303376   \n",
      "LDA                           0.707663           0.772773       0.292337   \n",
      "LogisticRegression            0.711717           0.783002       0.288283   \n",
      "QDA                           0.725726           0.795491       0.274274   \n",
      "SVM_linear                    0.716574           0.781522       0.283426   \n",
      "SVM_rbf                       0.878577           0.947086       0.121423   \n",
      "\n",
      "                    far_at_eer_train_44k  frr_at_eer_train_44k  accuracy_44k  \\\n",
      "model                                                                          \n",
      "GMM_logL_diff                   0.275314              0.275242      0.722410   \n",
      "GaussianNB                      0.303370              0.303382      0.693012   \n",
      "LDA                             0.292325              0.292350      0.702811   \n",
      "LogisticRegression              0.288294              0.288272      0.710201   \n",
      "QDA                             0.274266              0.274283      0.727229   \n",
      "SVM_linear                      0.283296              0.283556      0.714056   \n",
      "SVM_rbf                         0.121412              0.121433      0.853494   \n",
      "\n",
      "                    roc_auc_44k   eer_44k  far_at_eer_44k  frr_at_eer_44k  \n",
      "model                                                                      \n",
      "GMM_logL_diff          0.806071  0.277593        0.277354        0.277832  \n",
      "GaussianNB             0.762796  0.306989        0.306934        0.307043  \n",
      "LDA                    0.769894  0.297187        0.297392        0.296981  \n",
      "LogisticRegression     0.780571  0.289796        0.290076        0.289516  \n",
      "QDA                    0.799864  0.272770        0.272901        0.272639  \n",
      "SVM_linear             0.777050  0.285944        0.285941        0.285946  \n",
      "SVM_rbf                0.931174  0.146505        0.146628        0.146381  \n",
      "\n",
      "Features USED (44.1k / 25 ms):\n",
      "['dur_s', 'f0_mean_v', 'f0_std_v', 'f0_iqr_v', 'f0_cv_v', 'f0_range_v', 'f0_p10_v', 'f0_p90_v', 'rms_mean', 'rms_std', 'rms_cv', 'rms_iqr', 'rms_range', 'jitter_local', 'shimmer_local', 'f0_slope_hz_per_s', 'voice_pct', 'n_voiced_seg_per_s', 'mean_voiced_seg_ms', 'pause_ratio']\n",
      "\n",
      "Features USED (16k):\n",
      "['dur_s', 'f0_mean_v', 'f0_std_v', 'f0_iqr_v', 'f0_cv_v', 'f0_range_v', 'f0_p10_v', 'f0_p90_v', 'rms_mean', 'rms_std', 'rms_cv', 'rms_iqr', 'rms_range', 'jitter_local', 'f0_slope_hz_per_s', 'voice_pct', 'n_voiced_seg_per_s', 'mean_voiced_seg_ms', 'pause_ratio']\n",
      "\n",
      "===== Class balance for 16k_fullclip =====\n",
      "Unique speakers TRAIN: 24447\n",
      "Unique speakers TEST: 6112\n",
      "Class counts TRAIN [real, fake]: [12404 12509]\n",
      "Class counts TEST  [real, fake]: [3144 3081]\n",
      "Train % fake: 50.21%\n",
      "Test  % fake: 49.49%\n",
      "\n",
      "===== Class balance for 44k_25ms =====\n",
      "Unique speakers TRAIN: 24447\n",
      "Unique speakers TEST: 6112\n",
      "Class counts TRAIN [real, fake]: [12404 12509]\n",
      "Class counts TEST  [real, fake]: [3144 3081]\n",
      "Train % fake: 50.21%\n",
      "Test  % fake: 49.49%\n",
      "\n",
      "=== ALL DONE! ===\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# 11) Side-by-Side Comparison & Class Balance\n",
    "# =========================================\n",
    "\n",
    "# Comparison of 44.1k vs 16k\n",
    "m44 = res_44k['metrics'].set_index('model')\n",
    "m16 = res_16k['metrics'].set_index('model')\n",
    "comparison = m16.join(m44, how='outer', lsuffix='_16k', rsuffix='_44k')\n",
    "print('\\n=== SIDE-BY-SIDE COMPARISON (16k vs 44k) ===')\n",
    "print(comparison)\n",
    "\n",
    "print('\\nFeatures USED (44.1k / 25 ms):')\n",
    "print(res_44k['features_used'])\n",
    "print('\\nFeatures USED (16k):')\n",
    "print(res_16k['features_used'])\n",
    "\n",
    "# Class & speaker balance check\n",
    "def check_class_and_speaker_balance(df_all, tag):\n",
    "    print(f'\\n===== Class balance for {tag} =====')\n",
    "    y = df_all['label'].to_numpy().astype(int)\n",
    "    groups = df_all['group'].to_numpy()\n",
    "\n",
    "    gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=SEED)\n",
    "    train_idx, test_idx = next(gss.split(np.zeros(len(y)), y, groups=groups))\n",
    "\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    groups_train, groups_test = groups[train_idx], groups[test_idx]\n",
    "\n",
    "    print(f'Unique speakers TRAIN: {len(np.unique(groups_train))}')\n",
    "    print(f'Unique speakers TEST: {len(np.unique(groups_test))}')\n",
    "\n",
    "    train_counts = np.bincount(y_train, minlength=2)\n",
    "    test_counts = np.bincount(y_test, minlength=2)\n",
    "    print(f'Class counts TRAIN [real, fake]: {train_counts}')\n",
    "    print(f'Class counts TEST  [real, fake]: {test_counts}')\n",
    "    print(f'Train % fake: {100 * train_counts[1] / train_counts.sum():.2f}%')\n",
    "    print(f'Test  % fake: {100 * test_counts[1] / test_counts.sum():.2f}%')\n",
    "\n",
    "check_class_and_speaker_balance(df_all_16k, '16k_fullclip')\n",
    "check_class_and_speaker_balance(df_all_44k, '44k_25ms')\n",
    "\n",
    "print('\\n=== ALL DONE! ===')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
